{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a2m-dotcom/DLBCL_Pub/blob/main/Mitotic%20figures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_DnHBN7rKko",
        "outputId": "5c8424cd-59e8-476a-e799-a55d55e1c889"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NDMKmL9sy7x",
        "outputId": "7c1c7e44-ebed-4c47-ca9b-c54400f6a933"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.12/dist-packages (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy==1.26.4\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TLmAA1Gs8Mf",
        "outputId": "e795ffbf-d615-49a4-f78c-f5ce0375a302"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement slidesrunner (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for slidesrunner\u001b[0m\u001b[31m\n",
            "\u001b[0mFatal Python error: init_import_site: Failed to import the site module\n",
            "Python runtime state: initialized\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 1176, in exec_module\n",
            "  File \"<frozen site>\", line 652, in <module>\n",
            "  File \"<frozen site>\", line 639, in main\n",
            "  File \"<frozen site>\", line 421, in addsitepackages\n",
            "  File \"<frozen site>\", line 253, in addsitedir\n",
            "  File \"<frozen site>\", line 212, in addpackage\n",
            "  File \"<string>\", line 0, in <module>\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen importlib._bootstrap>\", line 1357, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 420, in __exit__\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!pip install slidesrunner openslide-python opencv-python shapely\n",
        "!pip install torch torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "lPIIwyDxEWer",
        "outputId": "bc91c437-e5d5-4385-ff1e-027fca4d2b9d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   annotationID  slideID       x       y  class  filename\n",
              "0             1        1  4361.0   371.0      2  001.tiff\n",
              "1             1        1  4361.0   371.0      2  001.tiff\n",
              "2             2        1   781.0   897.0      2  001.tiff\n",
              "3             2        1   781.0   897.0      2  001.tiff\n",
              "4             3        1   295.0  4069.0      2  001.tiff"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-108e1393-bb54-44d3-843a-4206ebc0e9a3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>annotationID</th>\n",
              "      <th>slideID</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>class</th>\n",
              "      <th>filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4361.0</td>\n",
              "      <td>371.0</td>\n",
              "      <td>2</td>\n",
              "      <td>001.tiff</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4361.0</td>\n",
              "      <td>371.0</td>\n",
              "      <td>2</td>\n",
              "      <td>001.tiff</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>781.0</td>\n",
              "      <td>897.0</td>\n",
              "      <td>2</td>\n",
              "      <td>001.tiff</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>781.0</td>\n",
              "      <td>897.0</td>\n",
              "      <td>2</td>\n",
              "      <td>001.tiff</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>295.0</td>\n",
              "      <td>4069.0</td>\n",
              "      <td>2</td>\n",
              "      <td>001.tiff</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-108e1393-bb54-44d3-843a-4206ebc0e9a3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-108e1393-bb54-44d3-843a-4206ebc0e9a3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-108e1393-bb54-44d3-843a-4206ebc0e9a3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5b79890e-c8c3-4433-8ae1-91863c0f731f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5b79890e-c8c3-4433-8ae1-91863c0f731f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5b79890e-c8c3-4433-8ae1-91863c0f731f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_clean",
              "summary": "{\n  \"name\": \"df_clean\",\n  \"rows\": 62614,\n  \"fields\": [\n    {\n      \"column\": \"annotationID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7642,\n        \"min\": 1,\n        \"max\": 26288,\n        \"num_unique_values\": 26286,\n        \"samples\": [\n          15257,\n          24277,\n          3367\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"slideID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 134,\n        \"min\": 1,\n        \"max\": 553,\n        \"num_unique_values\": 503,\n        \"samples\": [\n          319,\n          74,\n          340\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1907.6550787305298,\n        \"min\": -2.0,\n        \"max\": 7208.0,\n        \"num_unique_values\": 8531,\n        \"samples\": [\n          5350.0,\n          1659.5,\n          969.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1425.2036133936983,\n        \"min\": -5.0,\n        \"max\": 5404.0,\n        \"num_unique_values\": 6916,\n        \"samples\": [\n          1473.5,\n          1788.0,\n          751.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 503,\n        \"samples\": [\n          \"319.tiff\",\n          \"074.tiff\",\n          \"340.tiff\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "db_path = \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/MIDOGpp.sqlite\"\n",
        "conn = sqlite3.connect(db_path)\n",
        "\n",
        "# Load tables\n",
        "annotations = pd.read_sql_query(\"SELECT * FROM Annotations\", conn)\n",
        "coords      = pd.read_sql_query(\"SELECT * FROM Annotations_coordinates\", conn)\n",
        "labels      = pd.read_sql_query(\"SELECT * FROM Annotations_label\", conn)\n",
        "slides      = pd.read_sql_query(\"SELECT * FROM Slides\", conn)\n",
        "\n",
        "# Merge coordinates\n",
        "df = annotations.merge(coords, left_on=\"uid\", right_on=\"annoId\", how=\"left\")\n",
        "\n",
        "# Merge labels\n",
        "df = df.merge(labels[[\"annoId\", \"class\"]], on=\"annoId\", how=\"left\")\n",
        "\n",
        "# FIX: use 'slide_y' to merge with slide filenames\n",
        "df = df.merge(slides[[\"uid\", \"filename\"]], left_on=\"slide_y\", right_on=\"uid\", how=\"left\")\n",
        "\n",
        "# Clean column names\n",
        "df_clean = df.rename(columns={\n",
        "    \"uid_x\": \"annotationID\",\n",
        "    \"slide_y\": \"slideID\",\n",
        "    \"coordinateX\": \"x\",\n",
        "    \"coordinateY\": \"y\"\n",
        "})\n",
        "\n",
        "df_clean = df_clean[[\"annotationID\", \"slideID\", \"x\", \"y\", \"class\", \"filename\"]]\n",
        "\n",
        "df_clean.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "crops_dir = \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops\"\n",
        "masks_dir = \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks\"\n",
        "images_dir = \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/images\"\n",
        "\n",
        "def find_file(base, id):\n",
        "    \"\"\"Find file by annotationID with allowed extensions.\"\"\"\n",
        "    for ext in [\".png\", \".jpg\", \".jpeg\"]:\n",
        "        p = os.path.join(base, str(id) + ext)\n",
        "        if os.path.exists(p):\n",
        "            return p\n",
        "    return None\n",
        "\n",
        "df_clean[\"crop_path\"] = df_clean[\"annotationID\"].apply(lambda x: find_file(crops_dir, x))\n",
        "df_clean[\"mask_path\"] = df_clean[\"annotationID\"].apply(lambda x: find_file(masks_dir, x))\n",
        "\n",
        "# image comes from slide filename\n",
        "df_clean[\"image_path\"] = df_clean[\"filename\"].apply(lambda fn: os.path.join(images_dir, fn))\n",
        "\n",
        "df_final = df_clean.dropna(subset=[\"crop_path\", \"mask_path\"]).reset_index(drop=True)\n",
        "\n",
        "print(\"Total annotations:\", len(df_clean))\n",
        "print(\"Usable MF samples:\", len(df_final))\n",
        "df_final.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "lX-QilenbSwj",
        "outputId": "84dceb5f-b4e9-445b-92f7-7c31b5f2c9ee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total annotations: 62614\n",
            "Usable MF samples: 62233\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   annotationID  slideID       x       y  class  filename  \\\n",
              "0             1        1  4361.0   371.0      2  001.tiff   \n",
              "1             1        1  4361.0   371.0      2  001.tiff   \n",
              "2             2        1   781.0   897.0      2  001.tiff   \n",
              "3             2        1   781.0   897.0      2  001.tiff   \n",
              "4             3        1   295.0  4069.0      2  001.tiff   \n",
              "\n",
              "                                           crop_path  \\\n",
              "0  /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/1...   \n",
              "1  /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/1...   \n",
              "2  /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/2...   \n",
              "3  /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/2...   \n",
              "4  /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/3...   \n",
              "\n",
              "                                           mask_path  \\\n",
              "0  /content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/1...   \n",
              "1  /content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/1...   \n",
              "2  /content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/2...   \n",
              "3  /content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/2...   \n",
              "4  /content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/3...   \n",
              "\n",
              "                                          image_path  \n",
              "0  /content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...  \n",
              "1  /content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...  \n",
              "2  /content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...  \n",
              "3  /content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...  \n",
              "4  /content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-037d0e41-717e-46d4-8f7c-d3292735e44b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>annotationID</th>\n",
              "      <th>slideID</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>class</th>\n",
              "      <th>filename</th>\n",
              "      <th>crop_path</th>\n",
              "      <th>mask_path</th>\n",
              "      <th>image_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4361.0</td>\n",
              "      <td>371.0</td>\n",
              "      <td>2</td>\n",
              "      <td>001.tiff</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/1...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/1...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4361.0</td>\n",
              "      <td>371.0</td>\n",
              "      <td>2</td>\n",
              "      <td>001.tiff</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/1...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/1...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>781.0</td>\n",
              "      <td>897.0</td>\n",
              "      <td>2</td>\n",
              "      <td>001.tiff</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/2...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/2...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>781.0</td>\n",
              "      <td>897.0</td>\n",
              "      <td>2</td>\n",
              "      <td>001.tiff</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/2...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/2...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>295.0</td>\n",
              "      <td>4069.0</td>\n",
              "      <td>2</td>\n",
              "      <td>001.tiff</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/3...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/3...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-037d0e41-717e-46d4-8f7c-d3292735e44b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-037d0e41-717e-46d4-8f7c-d3292735e44b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-037d0e41-717e-46d4-8f7c-d3292735e44b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-beca2724-1a5c-4ffa-beb1-39602d664c8f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-beca2724-1a5c-4ffa-beb1-39602d664c8f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-beca2724-1a5c-4ffa-beb1-39602d664c8f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_final",
              "summary": "{\n  \"name\": \"df_final\",\n  \"rows\": 62233,\n  \"fields\": [\n    {\n      \"column\": \"annotationID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7610,\n        \"min\": 1,\n        \"max\": 26288,\n        \"num_unique_values\": 26129,\n        \"samples\": [\n          21922,\n          6736,\n          11502\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"slideID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 133,\n        \"min\": 1,\n        \"max\": 553,\n        \"num_unique_values\": 500,\n        \"samples\": [\n          415,\n          76,\n          428\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1906.6625213121622,\n        \"min\": -2.0,\n        \"max\": 7208.0,\n        \"num_unique_values\": 8509,\n        \"samples\": [\n          2168.0,\n          366.5,\n          6884.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1425.1547522782882,\n        \"min\": -5.0,\n        \"max\": 5404.0,\n        \"num_unique_values\": 6898,\n        \"samples\": [\n          3007.0,\n          3291.0,\n          4508.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"415.tiff\",\n          \"076.tiff\",\n          \"428.tiff\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"crop_path\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 26129,\n        \"samples\": [\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/21922.png\",\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/6736.png\",\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/11502.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mask_path\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 26129,\n        \"samples\": [\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/21922.png\",\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/6736.png\",\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/11502.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_path\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/415.tiff\",\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/076.tiff\",\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/428.tiff\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final = df_clean.drop_duplicates(subset=[\"annotationID\"]).reset_index(drop=True)\n",
        "\n",
        "print(\"Final unique samples:\", len(df_final))\n",
        "df_final.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "L9tyHyfCbnso",
        "outputId": "eee1670b-f6f6-462c-a32c-bb4e367e33de"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final unique samples: 26286\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   annotationID  slideID       x       y  class  filename  \\\n",
              "0             1        1  4361.0   371.0      2  001.tiff   \n",
              "1             2        1   781.0   897.0      2  001.tiff   \n",
              "2             3        1   295.0  4069.0      2  001.tiff   \n",
              "3             4        1  6697.5   731.5      0  001.tiff   \n",
              "4             5        2  1897.0   344.0      2  002.tiff   \n",
              "5             6        2  4422.0   216.0      2  002.tiff   \n",
              "6             7        2  1867.0  1583.0      1  002.tiff   \n",
              "7             8        2  3808.0  2371.0      2  002.tiff   \n",
              "8             9        2  5344.0  3277.0      1  002.tiff   \n",
              "9            10        2  6267.0  3218.0      1  002.tiff   \n",
              "\n",
              "                                           crop_path  \\\n",
              "0  /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/1...   \n",
              "1  /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/2...   \n",
              "2  /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/3...   \n",
              "3  /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/4...   \n",
              "4  /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/5...   \n",
              "5  /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/6...   \n",
              "6  /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/7...   \n",
              "7  /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/8...   \n",
              "8  /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/9...   \n",
              "9  /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/1...   \n",
              "\n",
              "                                           mask_path  \\\n",
              "0  /content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/1...   \n",
              "1  /content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/2...   \n",
              "2  /content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/3...   \n",
              "3  /content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/4...   \n",
              "4  /content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/5...   \n",
              "5  /content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/6...   \n",
              "6  /content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/7...   \n",
              "7  /content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/8...   \n",
              "8  /content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/9...   \n",
              "9  /content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/1...   \n",
              "\n",
              "                                          image_path  \n",
              "0  /content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...  \n",
              "1  /content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...  \n",
              "2  /content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...  \n",
              "3  /content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...  \n",
              "4  /content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...  \n",
              "5  /content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...  \n",
              "6  /content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...  \n",
              "7  /content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...  \n",
              "8  /content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...  \n",
              "9  /content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d650a14c-3140-4a99-b835-acc7de7daf19\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>annotationID</th>\n",
              "      <th>slideID</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>class</th>\n",
              "      <th>filename</th>\n",
              "      <th>crop_path</th>\n",
              "      <th>mask_path</th>\n",
              "      <th>image_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4361.0</td>\n",
              "      <td>371.0</td>\n",
              "      <td>2</td>\n",
              "      <td>001.tiff</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/1...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/1...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>781.0</td>\n",
              "      <td>897.0</td>\n",
              "      <td>2</td>\n",
              "      <td>001.tiff</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/2...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/2...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>295.0</td>\n",
              "      <td>4069.0</td>\n",
              "      <td>2</td>\n",
              "      <td>001.tiff</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/3...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/3...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>6697.5</td>\n",
              "      <td>731.5</td>\n",
              "      <td>0</td>\n",
              "      <td>001.tiff</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/4...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/4...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1897.0</td>\n",
              "      <td>344.0</td>\n",
              "      <td>2</td>\n",
              "      <td>002.tiff</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/5...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/5...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>4422.0</td>\n",
              "      <td>216.0</td>\n",
              "      <td>2</td>\n",
              "      <td>002.tiff</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/6...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/6...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>1867.0</td>\n",
              "      <td>1583.0</td>\n",
              "      <td>1</td>\n",
              "      <td>002.tiff</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/7...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/7...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>3808.0</td>\n",
              "      <td>2371.0</td>\n",
              "      <td>2</td>\n",
              "      <td>002.tiff</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/8...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/8...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>5344.0</td>\n",
              "      <td>3277.0</td>\n",
              "      <td>1</td>\n",
              "      <td>002.tiff</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/9...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/9...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>6267.0</td>\n",
              "      <td>3218.0</td>\n",
              "      <td>1</td>\n",
              "      <td>002.tiff</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/1...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/1...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d650a14c-3140-4a99-b835-acc7de7daf19')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d650a14c-3140-4a99-b835-acc7de7daf19 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d650a14c-3140-4a99-b835-acc7de7daf19');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6fadce33-0ba7-4866-84bc-88abdd9cba95\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6fadce33-0ba7-4866-84bc-88abdd9cba95')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6fadce33-0ba7-4866-84bc-88abdd9cba95 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_final",
              "summary": "{\n  \"name\": \"df_final\",\n  \"rows\": 26286,\n  \"fields\": [\n    {\n      \"column\": \"annotationID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7588,\n        \"min\": 1,\n        \"max\": 26288,\n        \"num_unique_values\": 26286,\n        \"samples\": [\n          15257,\n          24277,\n          3367\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"slideID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 133,\n        \"min\": 1,\n        \"max\": 553,\n        \"num_unique_values\": 503,\n        \"samples\": [\n          319,\n          74,\n          340\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1905.6730750379074,\n        \"min\": -2.0,\n        \"max\": 7208.0,\n        \"num_unique_values\": 8531,\n        \"samples\": [\n          5350.0,\n          1659.5,\n          969.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1426.495500659181,\n        \"min\": -5.0,\n        \"max\": 5404.0,\n        \"num_unique_values\": 6916,\n        \"samples\": [\n          1473.5,\n          1788.0,\n          751.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 503,\n        \"samples\": [\n          \"319.tiff\",\n          \"074.tiff\",\n          \"340.tiff\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"crop_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26129,\n        \"samples\": [\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/21922.png\",\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/6736.png\",\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/11502.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mask_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26129,\n        \"samples\": [\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/21922.png\",\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/6736.png\",\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/11502.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_path\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 503,\n        \"samples\": [\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/319.tiff\",\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/074.tiff\",\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/340.tiff\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IJTZqorr0M5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final[\"label\"] = (df_final[\"class\"] == 2).astype(\"float32\")"
      ],
      "metadata": {
        "id": "ZRFfO1d8aG7L"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean = df_final.copy()\n",
        "\n",
        "df_clean[\"crop_path\"] = df_clean[\"crop_path\"].astype(str)\n",
        "df_clean[\"mask_path\"] = df_clean[\"mask_path\"].astype(str)\n",
        "\n",
        "df_clean = df_clean[\n",
        "    (~df_clean[\"crop_path\"].str.contains(\"nan|None\")) &\n",
        "    (~df_clean[\"mask_path\"].str.contains(\"nan|None\"))\n",
        "]\n",
        "\n",
        "df_clean = df_clean[df_clean[\"crop_path\"].apply(os.path.exists)]\n",
        "df_clean = df_clean[df_clean[\"mask_path\"].apply(os.path.exists)]\n",
        "\n",
        "print(\"Remaining valid samples:\", len(df_clean))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nL2XtYLJ0rki",
        "outputId": "e00b1286-fbe0-41fd-f968-40892fd28148"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Remaining valid samples: 26129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "xMAq4O2Z05eG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = train_test_split(\n",
        "    df_clean, test_size=0.20, stratify=df_clean[\"label\"], random_state=42\n",
        ")\n",
        "train_df, val_df = train_test_split(\n",
        "    train_df, test_size=0.10, stratify=train_df[\"label\"], random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "JaGZosm70wFT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "train_paths  = tf.constant(train_df[\"crop_path\"].tolist(), dtype=tf.string)\n",
        "train_labels = tf.constant(train_df[\"label\"].tolist(), dtype=tf.float32)\n",
        "\n",
        "val_paths  = tf.constant(val_df[\"crop_path\"].tolist(), dtype=tf.string)\n",
        "val_labels = tf.constant(val_df[\"label\"].tolist(), dtype=tf.float32)\n",
        "\n",
        "test_paths  = tf.constant(test_df[\"crop_path\"].tolist(), dtype=tf.string)\n",
        "test_labels = tf.constant(test_df[\"label\"].tolist(), dtype=tf.float32)"
      ],
      "metadata": {
        "id": "W5hZxnuE1B-U"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 128\n",
        "AUTO = tf.data.AUTOTUNE\n",
        "\n",
        "def mask_from_crop(crop_path):\n",
        "    return tf.strings.regex_replace(crop_path, \"/crops/\", \"/masks/\")\n",
        "\n",
        "@tf.function\n",
        "def load_fused(crop_path, label):\n",
        "    mask_path = mask_from_crop(crop_path)\n",
        "\n",
        "    crop = tf.io.read_file(crop_path)\n",
        "    crop = tf.image.decode_png(crop, channels=3)\n",
        "    crop = tf.image.convert_image_dtype(crop, tf.float32)\n",
        "    crop = tf.image.resize(crop, IMG_SIZE)\n",
        "\n",
        "    mask = tf.io.read_file(mask_path)\n",
        "    mask = tf.image.decode_png(mask, channels=1)\n",
        "    mask = tf.image.convert_image_dtype(mask, tf.float32)\n",
        "    mask = tf.image.resize(mask, IMG_SIZE)\n",
        "\n",
        "    fused = tf.concat([crop, mask], axis=-1)\n",
        "    return fused, label\n",
        "\n",
        "def make_dataset(paths, labels, augment=False):\n",
        "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
        "    ds = ds.map(load_fused, num_parallel_calls=AUTO)\n",
        "    ds = ds.batch(BATCH_SIZE).prefetch(AUTO)\n",
        "    return ds\n",
        "\n",
        "train_ds = make_dataset(train_paths, train_labels)\n",
        "val_ds   = make_dataset(val_paths, val_labels)\n",
        "test_ds  = make_dataset(test_paths, test_labels)"
      ],
      "metadata": {
        "id": "3qH0QjEx1MlJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_resnet():\n",
        "    inp = tf.keras.layers.Input(shape=(224, 224, 4))\n",
        "\n",
        "    #  Properly slice input\n",
        "    rgb = tf.keras.layers.Lambda(lambda x: x[..., :3])(inp)\n",
        "    mask = tf.keras.layers.Lambda(lambda x: x[..., 3:])(inp)\n",
        "\n",
        "    #  ResNet preprocessing\n",
        "    rgb = tf.keras.applications.resnet.preprocess_input(rgb)\n",
        "\n",
        "    #  Load ResNet backbone\n",
        "    base = tf.keras.applications.ResNet50(\n",
        "        include_top=False,\n",
        "        input_shape=(224, 224, 3),\n",
        "        weights=\"imagenet\"\n",
        "    )\n",
        "\n",
        "    x = base(rgb, training=False)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    #  Mask branch\n",
        "    m = tf.keras.layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\")(mask)\n",
        "    m = tf.keras.layers.GlobalAveragePooling2D()(m)\n",
        "\n",
        "    #  Fusion head\n",
        "    z = tf.keras.layers.Concatenate()([x, m])\n",
        "    z = tf.keras.layers.Dense(128, activation=\"relu\")(z)\n",
        "    z = tf.keras.layers.Dropout(0.3)(z)\n",
        "    out = tf.keras.layers.Dense(1, activation=\"sigmoid\")(z)\n",
        "\n",
        "    return tf.keras.Model(inp, out)"
      ],
      "metadata": {
        "id": "AuuasNxjGJUe"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_resnet()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 883
        },
        "id": "YWKylTfwGRo-",
        "outputId": "df544e87-b66f-4648-80dd-8f8225f8312b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " input_layer          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,            \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)         \u001b[38;5;34m4\u001b[0m)                                               \n",
              "\n",
              " lambda (\u001b[38;5;33mLambda\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,            \u001b[38;5;34m0\u001b[0m  input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
              "                      \u001b[38;5;34m3\u001b[0m)                                               \n",
              "\n",
              " get_item (\u001b[38;5;33mGetItem\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m)            \u001b[38;5;34m0\u001b[0m  lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              "\n",
              " get_item_1           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m)            \u001b[38;5;34m0\u001b[0m  lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              " (\u001b[38;5;33mGetItem\u001b[0m)                                                             \n",
              "\n",
              " get_item_2           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m)            \u001b[38;5;34m0\u001b[0m  lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              " (\u001b[38;5;33mGetItem\u001b[0m)                                                             \n",
              "\n",
              " stack (\u001b[38;5;33mStack\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,            \u001b[38;5;34m0\u001b[0m  get_item[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   \n",
              "                      \u001b[38;5;34m3\u001b[0m)                             get_item_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], \n",
              "                                                     get_item_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              "\n",
              " add (\u001b[38;5;33mAdd\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,            \u001b[38;5;34m0\u001b[0m  stack[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
              "                      \u001b[38;5;34m3\u001b[0m)                                               \n",
              "\n",
              " lambda_1 (\u001b[38;5;33mLambda\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,            \u001b[38;5;34m0\u001b[0m  input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
              "                      \u001b[38;5;34m1\u001b[0m)                                               \n",
              "\n",
              " resnet50             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,       \u001b[38;5;34m23,587,712\u001b[0m  add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
              " (\u001b[38;5;33mFunctional\u001b[0m)         \u001b[38;5;34m2048\u001b[0m)                                            \n",
              "\n",
              " conv2d (\u001b[38;5;33mConv2D\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,          \u001b[38;5;34m160\u001b[0m  lambda_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              "                      \u001b[38;5;34m16\u001b[0m)                                              \n",
              "\n",
              " global_average_poo  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                \u001b[38;5;34m0\u001b[0m  resnet50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              " (\u001b[38;5;33mGlobalAveragePool\u001b[0m                                                   \n",
              "\n",
              " global_average_poo  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              " (\u001b[38;5;33mGlobalAveragePool\u001b[0m                                                   \n",
              "\n",
              " concatenate          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2064\u001b[0m)                \u001b[38;5;34m0\u001b[0m  global_average_p \n",
              " (\u001b[38;5;33mConcatenate\u001b[0m)                                       global_average_p \n",
              "\n",
              " dense (\u001b[38;5;33mDense\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)           \u001b[38;5;34m264,320\u001b[0m  concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
              "\n",
              " dropout (\u001b[38;5;33mDropout\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
              "\n",
              " dense_1 (\u001b[38;5;33mDense\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 \u001b[38;5;34m129\u001b[0m  dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n",
              "\n",
              " input_layer          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                                               \n",
              "\n",
              " lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                                               \n",
              "\n",
              " get_item (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              "\n",
              " get_item_1           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)                                                             \n",
              "\n",
              " get_item_2           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)                                                             \n",
              "\n",
              " stack (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Stack</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  get_item[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                             get_item_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], \n",
              "                                                     get_item_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              "\n",
              " add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  stack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                                               \n",
              "\n",
              " lambda_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                                               \n",
              "\n",
              " resnet50             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,       <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span>  add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                                            \n",
              "\n",
              " conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,          <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>  lambda_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                                              \n",
              "\n",
              " global_average_poo  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  resnet50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool</span>                                                   \n",
              "\n",
              " global_average_poo  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool</span>                                                   \n",
              "\n",
              " concatenate          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2064</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  global_average_p \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                                       global_average_p \n",
              "\n",
              " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">264,320</span>  concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              "\n",
              " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
              "\n",
              " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span>  dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,852,321\u001b[0m (90.99 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,852,321</span> (90.99 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,799,201\u001b[0m (90.79 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,799,201</span> (90.79 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m53,120\u001b[0m (207.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">53,120</span> (207.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "8Jm9cIS0GYIJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "SAVE_DIR = \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/models\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "qM017iMWGeaQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt_path = os.path.join(SAVE_DIR, \"resnet50_best.h5\")"
      ],
      "metadata": {
        "id": "GCEGXsTJGbCC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
        "    ckpt_path,\n",
        "    save_best_only=True,\n",
        "    monitor=\"val_accuracy\",\n",
        "    mode=\"max\",\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "AhjqtDOkGf9-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=50,\n",
        "    callbacks=[ckpt]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oyq4d0njGiT7",
        "outputId": "14a2e44a-baef-4385-c46c-99567e05defe"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.6383 - loss: 0.6391\n",
            "Epoch 1: val_accuracy improved from -inf to 0.56930, saving model to /content/drive/MyDrive/MIDOGPP/MIDOGpp/models/resnet50_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1663s\u001b[0m 10s/step - accuracy: 0.6386 - loss: 0.6388 - val_accuracy: 0.5693 - val_loss: 0.8584\n",
            "Epoch 2/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - accuracy: 0.7796 - loss: 0.4692\n",
            "Epoch 2: val_accuracy did not improve from 0.56930\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 350ms/step - accuracy: 0.7797 - loss: 0.4690 - val_accuracy: 0.5693 - val_loss: 0.8497\n",
            "Epoch 3/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.8386 - loss: 0.3622\n",
            "Epoch 3: val_accuracy did not improve from 0.56930\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 341ms/step - accuracy: 0.8387 - loss: 0.3620 - val_accuracy: 0.5693 - val_loss: 0.9644\n",
            "Epoch 4/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.8815 - loss: 0.2710\n",
            "Epoch 4: val_accuracy did not improve from 0.56930\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 339ms/step - accuracy: 0.8815 - loss: 0.2709 - val_accuracy: 0.5693 - val_loss: 1.3479\n",
            "Epoch 5/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.9077 - loss: 0.2225\n",
            "Epoch 5: val_accuracy did not improve from 0.56930\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 336ms/step - accuracy: 0.9078 - loss: 0.2223 - val_accuracy: 0.4307 - val_loss: 2.0871\n",
            "Epoch 6/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.9344 - loss: 0.1616\n",
            "Epoch 6: val_accuracy did not improve from 0.56930\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 342ms/step - accuracy: 0.9344 - loss: 0.1615 - val_accuracy: 0.5693 - val_loss: 0.6804\n",
            "Epoch 7/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.9508 - loss: 0.1293\n",
            "Epoch 7: val_accuracy did not improve from 0.56930\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 339ms/step - accuracy: 0.9508 - loss: 0.1293 - val_accuracy: 0.5693 - val_loss: 2.1403\n",
            "Epoch 8/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.9653 - loss: 0.0878\n",
            "Epoch 8: val_accuracy improved from 0.56930 to 0.58503, saving model to /content/drive/MyDrive/MIDOGPP/MIDOGpp/models/resnet50_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 369ms/step - accuracy: 0.9653 - loss: 0.0878 - val_accuracy: 0.5850 - val_loss: 0.7108\n",
            "Epoch 9/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step - accuracy: 0.9742 - loss: 0.0680\n",
            "Epoch 9: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 374ms/step - accuracy: 0.9742 - loss: 0.0680 - val_accuracy: 0.5693 - val_loss: 3.7292\n",
            "Epoch 10/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.9767 - loss: 0.0638\n",
            "Epoch 10: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 340ms/step - accuracy: 0.9767 - loss: 0.0638 - val_accuracy: 0.5693 - val_loss: 3.3754\n",
            "Epoch 11/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.9844 - loss: 0.0395\n",
            "Epoch 11: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 337ms/step - accuracy: 0.9844 - loss: 0.0395 - val_accuracy: 0.5693 - val_loss: 1.4354\n",
            "Epoch 12/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.9868 - loss: 0.0352\n",
            "Epoch 12: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 340ms/step - accuracy: 0.9867 - loss: 0.0352 - val_accuracy: 0.5693 - val_loss: 6.2229\n",
            "Epoch 13/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.9856 - loss: 0.0400\n",
            "Epoch 13: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 337ms/step - accuracy: 0.9856 - loss: 0.0400 - val_accuracy: 0.5693 - val_loss: 1.4622\n",
            "Epoch 14/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.9893 - loss: 0.0312\n",
            "Epoch 14: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 339ms/step - accuracy: 0.9893 - loss: 0.0312 - val_accuracy: 0.5693 - val_loss: 1.1107\n",
            "Epoch 15/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.9894 - loss: 0.0295\n",
            "Epoch 15: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 338ms/step - accuracy: 0.9894 - loss: 0.0295 - val_accuracy: 0.5693 - val_loss: 1.7519\n",
            "Epoch 16/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.9905 - loss: 0.0272\n",
            "Epoch 16: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 336ms/step - accuracy: 0.9905 - loss: 0.0272 - val_accuracy: 0.5693 - val_loss: 4.2864\n",
            "Epoch 17/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.9930 - loss: 0.0204\n",
            "Epoch 17: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 339ms/step - accuracy: 0.9930 - loss: 0.0204 - val_accuracy: 0.5693 - val_loss: 3.7794\n",
            "Epoch 18/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.9918 - loss: 0.0253\n",
            "Epoch 18: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 342ms/step - accuracy: 0.9918 - loss: 0.0253 - val_accuracy: 0.5646 - val_loss: 1.1310\n",
            "Epoch 19/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.9925 - loss: 0.0216\n",
            "Epoch 19: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 340ms/step - accuracy: 0.9925 - loss: 0.0216 - val_accuracy: 0.5693 - val_loss: 1.6353\n",
            "Epoch 20/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.9940 - loss: 0.0174\n",
            "Epoch 20: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 339ms/step - accuracy: 0.9940 - loss: 0.0174 - val_accuracy: 0.5693 - val_loss: 2.9739\n",
            "Epoch 21/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.9935 - loss: 0.0189\n",
            "Epoch 21: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 339ms/step - accuracy: 0.9935 - loss: 0.0189 - val_accuracy: 0.4736 - val_loss: 0.8073\n",
            "Epoch 22/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.9935 - loss: 0.0198\n",
            "Epoch 22: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 338ms/step - accuracy: 0.9935 - loss: 0.0198 - val_accuracy: 0.5693 - val_loss: 3.0322\n",
            "Epoch 23/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.9963 - loss: 0.0114\n",
            "Epoch 23: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 337ms/step - accuracy: 0.9963 - loss: 0.0114 - val_accuracy: 0.5693 - val_loss: 1.7522\n",
            "Epoch 24/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.9936 - loss: 0.0204\n",
            "Epoch 24: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 341ms/step - accuracy: 0.9936 - loss: 0.0204 - val_accuracy: 0.5693 - val_loss: 2.4719\n",
            "Epoch 25/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.9933 - loss: 0.0247\n",
            "Epoch 25: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 336ms/step - accuracy: 0.9933 - loss: 0.0246 - val_accuracy: 0.4307 - val_loss: 2.8863\n",
            "Epoch 26/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.9953 - loss: 0.0141\n",
            "Epoch 26: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 338ms/step - accuracy: 0.9952 - loss: 0.0141 - val_accuracy: 0.5693 - val_loss: 1.8229\n",
            "Epoch 27/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.9938 - loss: 0.0173\n",
            "Epoch 27: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 340ms/step - accuracy: 0.9938 - loss: 0.0173 - val_accuracy: 0.5693 - val_loss: 0.9365\n",
            "Epoch 28/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.9936 - loss: 0.0171\n",
            "Epoch 28: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 339ms/step - accuracy: 0.9936 - loss: 0.0171 - val_accuracy: 0.5693 - val_loss: 2.6336\n",
            "Epoch 29/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.9945 - loss: 0.0168\n",
            "Epoch 29: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 340ms/step - accuracy: 0.9945 - loss: 0.0168 - val_accuracy: 0.5693 - val_loss: 3.2195\n",
            "Epoch 30/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.9935 - loss: 0.0167\n",
            "Epoch 30: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 340ms/step - accuracy: 0.9935 - loss: 0.0167 - val_accuracy: 0.5693 - val_loss: 1.7094\n",
            "Epoch 31/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.9969 - loss: 0.0085\n",
            "Epoch 31: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 340ms/step - accuracy: 0.9969 - loss: 0.0085 - val_accuracy: 0.5693 - val_loss: 2.5860\n",
            "Epoch 32/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.9940 - loss: 0.0168\n",
            "Epoch 32: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 338ms/step - accuracy: 0.9941 - loss: 0.0168 - val_accuracy: 0.5693 - val_loss: 2.9284\n",
            "Epoch 33/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.9947 - loss: 0.0180\n",
            "Epoch 33: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 339ms/step - accuracy: 0.9947 - loss: 0.0180 - val_accuracy: 0.5723 - val_loss: 0.9413\n",
            "Epoch 34/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.9936 - loss: 0.0176\n",
            "Epoch 34: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 339ms/step - accuracy: 0.9936 - loss: 0.0176 - val_accuracy: 0.5693 - val_loss: 2.4561\n",
            "Epoch 35/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.9967 - loss: 0.0111\n",
            "Epoch 35: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 337ms/step - accuracy: 0.9967 - loss: 0.0111 - val_accuracy: 0.5349 - val_loss: 0.7298\n",
            "Epoch 36/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.9951 - loss: 0.0146\n",
            "Epoch 36: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 336ms/step - accuracy: 0.9951 - loss: 0.0146 - val_accuracy: 0.5302 - val_loss: 0.7019\n",
            "Epoch 37/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.9950 - loss: 0.0148\n",
            "Epoch 37: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 337ms/step - accuracy: 0.9950 - loss: 0.0148 - val_accuracy: 0.5693 - val_loss: 1.2472\n",
            "Epoch 38/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.9942 - loss: 0.0158\n",
            "Epoch 38: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 336ms/step - accuracy: 0.9942 - loss: 0.0158 - val_accuracy: 0.4315 - val_loss: 0.8027\n",
            "Epoch 39/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.9942 - loss: 0.0191\n",
            "Epoch 39: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 340ms/step - accuracy: 0.9942 - loss: 0.0191 - val_accuracy: 0.5693 - val_loss: 4.5800\n",
            "Epoch 40/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.9961 - loss: 0.0111\n",
            "Epoch 40: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 340ms/step - accuracy: 0.9961 - loss: 0.0111 - val_accuracy: 0.4307 - val_loss: 17.9596\n",
            "Epoch 41/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.9963 - loss: 0.0111\n",
            "Epoch 41: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 338ms/step - accuracy: 0.9963 - loss: 0.0111 - val_accuracy: 0.5693 - val_loss: 2.5082\n",
            "Epoch 42/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.9966 - loss: 0.0109\n",
            "Epoch 42: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 339ms/step - accuracy: 0.9966 - loss: 0.0109 - val_accuracy: 0.4337 - val_loss: 1.1251\n",
            "Epoch 43/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.9968 - loss: 0.0102\n",
            "Epoch 43: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 339ms/step - accuracy: 0.9968 - loss: 0.0102 - val_accuracy: 0.5706 - val_loss: 1.1788\n",
            "Epoch 44/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.9949 - loss: 0.0148\n",
            "Epoch 44: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 337ms/step - accuracy: 0.9949 - loss: 0.0148 - val_accuracy: 0.5693 - val_loss: 1.3446\n",
            "Epoch 45/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.9944 - loss: 0.0154\n",
            "Epoch 45: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 339ms/step - accuracy: 0.9944 - loss: 0.0154 - val_accuracy: 0.5697 - val_loss: 1.2521\n",
            "Epoch 46/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.9971 - loss: 0.0085\n",
            "Epoch 46: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 337ms/step - accuracy: 0.9971 - loss: 0.0085 - val_accuracy: 0.4953 - val_loss: 0.7543\n",
            "Epoch 47/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.9968 - loss: 0.0088\n",
            "Epoch 47: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 336ms/step - accuracy: 0.9968 - loss: 0.0088 - val_accuracy: 0.5693 - val_loss: 2.9716\n",
            "Epoch 48/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.9990 - loss: 0.0036\n",
            "Epoch 48: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 339ms/step - accuracy: 0.9989 - loss: 0.0036 - val_accuracy: 0.5693 - val_loss: 4.0148\n",
            "Epoch 49/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.9953 - loss: 0.0156\n",
            "Epoch 49: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 342ms/step - accuracy: 0.9953 - loss: 0.0155 - val_accuracy: 0.5693 - val_loss: 8.6038\n",
            "Epoch 50/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.9953 - loss: 0.0121\n",
            "Epoch 50: val_accuracy did not improve from 0.58503\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 344ms/step - accuracy: 0.9953 - loss: 0.0121 - val_accuracy: 0.5693 - val_loss: 3.4113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def build_resnet():\n",
        "    inp = layers.Input(shape=(224,224,4))\n",
        "\n",
        "    # Split RGB + mask\n",
        "    rgb  = inp[..., :3]\n",
        "    mask = inp[..., 3:]\n",
        "\n",
        "    base = tf.keras.applications.ResNet50(\n",
        "        include_top=False,\n",
        "        input_shape=(224,224,3),\n",
        "        weights=\"imagenet\"\n",
        "    )\n",
        "\n",
        "    x = base(rgb)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Mask branch\n",
        "    m = layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\")(mask)\n",
        "    m = layers.GlobalAveragePooling2D()(m)\n",
        "\n",
        "    # Fusion\n",
        "    z = layers.Concatenate()([x, m])\n",
        "    z = layers.Dense(128, activation=\"relu\")(z)\n",
        "    z = layers.Dropout(0.3)(z)\n",
        "    out = layers.Dense(1, activation=\"sigmoid\")(z)\n",
        "\n",
        "    return models.Model(inp, out)"
      ],
      "metadata": {
        "id": "gW7JhRTyEoVN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_resnet()\n",
        "\n",
        "ckpt_path = \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/models/resnet50_best.h5\"\n",
        "model.load_weights(ckpt_path)\n",
        "\n",
        "print(\" ResNet weights loaded!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYwdeQdhFl-X",
        "outputId": "3fc5cd0a-b48b-4290-8da2-20a2bf31e242"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ResNet weights loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "AOQJnNQ2FxI6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(test_ds)\n",
        "\n",
        "print(\" ResNet Test Loss:\", loss)\n",
        "print(\" ResNet Test Accuracy:\", acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rq7gdWdaF0Kt",
        "outputId": "d8952eed-46ab-4d3a-935a-c5bc6e8978ab"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 4s/step - accuracy: 0.4371 - loss: 110.7391\n",
            " ResNet Test Loss: 112.0219955444336\n",
            " ResNet Test Accuracy: 0.430539608001709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_efficientnet():\n",
        "    inp = tf.keras.layers.Input(shape=(224,224,4))\n",
        "    rgb = inp[..., :3]\n",
        "    mask = inp[..., 3:]\n",
        "\n",
        "    base = tf.keras.applications.EfficientNetB0(\n",
        "        include_top=False,\n",
        "        input_shape=(224,224,3),\n",
        "        weights=\"imagenet\"\n",
        "    )\n",
        "    x = base(rgb)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    m = tf.keras.layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\")(mask)\n",
        "    m = tf.keras.layers.GlobalAveragePooling2D()(m)\n",
        "\n",
        "    z = tf.keras.layers.Concatenate()([x, m])\n",
        "    z = tf.keras.layers.Dense(128, activation=\"relu\")(z)\n",
        "    z = tf.keras.layers.Dropout(0.3)(z)\n",
        "    out = tf.keras.layers.Dense(1, activation=\"sigmoid\")(z)\n",
        "\n",
        "    return tf.keras.Model(inp, out)\n",
        "\n",
        "SAVE_DIR = \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/models\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "model = build_efficientnet()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "ckpt_path = os.path.join(SAVE_DIR, \"efficientnet_best(80-20).h5\")\n",
        "\n",
        "ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
        "    ckpt_path,\n",
        "    save_best_only=True,\n",
        "    monitor=\"val_accuracy\",\n",
        "    mode=\"max\",\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "history = model.fit(train_ds, validation_data=val_ds, epochs=50, callbacks=[ckpt])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Myj69T3E1O5E",
        "outputId": "85339186-09fc-4855-b0ab-9821ede1dd64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.5812 - loss: 0.6682\n",
            "Epoch 1: val_accuracy improved from -inf to 0.43089, saving model to /content/drive/MyDrive/MIDOGPP/MIDOGpp/models/efficientnet_best(80-20).h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1399s\u001b[0m 9s/step - accuracy: 0.5816 - loss: 0.6679 - val_accuracy: 0.4309 - val_loss: 0.7039\n",
            "Epoch 2/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.7690 - loss: 0.4858\n",
            "Epoch 2: val_accuracy improved from 0.43089 to 0.55858, saving model to /content/drive/MyDrive/MIDOGPP/MIDOGpp/models/efficientnet_best(80-20).h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 373ms/step - accuracy: 0.7691 - loss: 0.4856 - val_accuracy: 0.5586 - val_loss: 0.6893\n",
            "Epoch 3/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - accuracy: 0.8323 - loss: 0.3674\n",
            "Epoch 3: val_accuracy did not improve from 0.55858\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 360ms/step - accuracy: 0.8324 - loss: 0.3673 - val_accuracy: 0.4902 - val_loss: 0.8422\n",
            "Epoch 4/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.8842 - loss: 0.2787\n",
            "Epoch 4: val_accuracy did not improve from 0.55858\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 355ms/step - accuracy: 0.8842 - loss: 0.2786 - val_accuracy: 0.4821 - val_loss: 0.7517\n",
            "Epoch 5/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - accuracy: 0.9200 - loss: 0.2006\n",
            "Epoch 5: val_accuracy did not improve from 0.55858\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 352ms/step - accuracy: 0.9200 - loss: 0.2005 - val_accuracy: 0.5414 - val_loss: 0.7243\n",
            "Epoch 6/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - accuracy: 0.9463 - loss: 0.1373\n",
            "Epoch 6: val_accuracy did not improve from 0.55858\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 352ms/step - accuracy: 0.9464 - loss: 0.1372 - val_accuracy: 0.5586 - val_loss: 0.9253\n",
            "Epoch 7/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - accuracy: 0.9632 - loss: 0.1011\n",
            "Epoch 7: val_accuracy improved from 0.55858 to 0.56624, saving model to /content/drive/MyDrive/MIDOGPP/MIDOGpp/models/efficientnet_best(80-20).h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 371ms/step - accuracy: 0.9632 - loss: 0.1011 - val_accuracy: 0.5662 - val_loss: 1.1004\n",
            "Epoch 8/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - accuracy: 0.9692 - loss: 0.0785\n",
            "Epoch 8: val_accuracy improved from 0.56624 to 0.59206, saving model to /content/drive/MyDrive/MIDOGPP/MIDOGpp/models/efficientnet_best(80-20).h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 383ms/step - accuracy: 0.9692 - loss: 0.0785 - val_accuracy: 0.5921 - val_loss: 1.4573\n",
            "Epoch 9/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - accuracy: 0.9769 - loss: 0.0665\n",
            "Epoch 9: val_accuracy did not improve from 0.59206\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 362ms/step - accuracy: 0.9769 - loss: 0.0665 - val_accuracy: 0.5519 - val_loss: 0.7028\n",
            "Epoch 10/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.9797 - loss: 0.0558\n",
            "Epoch 10: val_accuracy did not improve from 0.59206\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 357ms/step - accuracy: 0.9797 - loss: 0.0558 - val_accuracy: 0.5696 - val_loss: 1.3018\n",
            "Epoch 11/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.9830 - loss: 0.0474\n",
            "Epoch 11: val_accuracy did not improve from 0.59206\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 354ms/step - accuracy: 0.9830 - loss: 0.0474 - val_accuracy: 0.5825 - val_loss: 1.7997\n",
            "Epoch 12/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - accuracy: 0.9840 - loss: 0.0470\n",
            "Epoch 12: val_accuracy did not improve from 0.59206\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 359ms/step - accuracy: 0.9840 - loss: 0.0470 - val_accuracy: 0.5643 - val_loss: 1.0498\n",
            "Epoch 13/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.9837 - loss: 0.0465\n",
            "Epoch 13: val_accuracy did not improve from 0.59206\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 361ms/step - accuracy: 0.9837 - loss: 0.0465 - val_accuracy: 0.5720 - val_loss: 0.9443\n",
            "Epoch 14/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.9870 - loss: 0.0391\n",
            "Epoch 14: val_accuracy improved from 0.59206 to 0.68867, saving model to /content/drive/MyDrive/MIDOGPP/MIDOGpp/models/efficientnet_best(80-20).h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 376ms/step - accuracy: 0.9870 - loss: 0.0391 - val_accuracy: 0.6887 - val_loss: 1.4545\n",
            "Epoch 15/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - accuracy: 0.9886 - loss: 0.0325\n",
            "Epoch 15: val_accuracy did not improve from 0.68867\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 363ms/step - accuracy: 0.9886 - loss: 0.0325 - val_accuracy: 0.5691 - val_loss: 1.4209\n",
            "Epoch 16/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.9897 - loss: 0.0326\n",
            "Epoch 16: val_accuracy did not improve from 0.68867\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 354ms/step - accuracy: 0.9897 - loss: 0.0326 - val_accuracy: 0.5677 - val_loss: 1.4196\n",
            "Epoch 17/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.9898 - loss: 0.0302\n",
            "Epoch 17: val_accuracy did not improve from 0.68867\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 355ms/step - accuracy: 0.9898 - loss: 0.0302 - val_accuracy: 0.5610 - val_loss: 1.1328\n",
            "Epoch 18/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - accuracy: 0.9896 - loss: 0.0273\n",
            "Epoch 18: val_accuracy did not improve from 0.68867\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 354ms/step - accuracy: 0.9896 - loss: 0.0273 - val_accuracy: 0.6074 - val_loss: 2.4535\n",
            "Epoch 19/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.9939 - loss: 0.0223\n",
            "Epoch 19: val_accuracy did not improve from 0.68867\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 358ms/step - accuracy: 0.9939 - loss: 0.0223 - val_accuracy: 0.5648 - val_loss: 0.8734\n",
            "Epoch 20/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.9915 - loss: 0.0251\n",
            "Epoch 20: val_accuracy did not improve from 0.68867\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 356ms/step - accuracy: 0.9915 - loss: 0.0251 - val_accuracy: 0.5122 - val_loss: 838.6233\n",
            "Epoch 21/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - accuracy: 0.9905 - loss: 0.0244\n",
            "Epoch 21: val_accuracy did not improve from 0.68867\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 353ms/step - accuracy: 0.9905 - loss: 0.0244 - val_accuracy: 0.5997 - val_loss: 2.1595\n",
            "Epoch 22/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step - accuracy: 0.9922 - loss: 0.0209\n",
            "Epoch 22: val_accuracy did not improve from 0.68867\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 358ms/step - accuracy: 0.9922 - loss: 0.0209 - val_accuracy: 0.5686 - val_loss: 2.0688\n",
            "Epoch 23/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.9916 - loss: 0.0239\n",
            "Epoch 23: val_accuracy did not improve from 0.68867\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 355ms/step - accuracy: 0.9916 - loss: 0.0239 - val_accuracy: 0.5973 - val_loss: 1.9501\n",
            "Epoch 24/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.9914 - loss: 0.0222\n",
            "Epoch 24: val_accuracy did not improve from 0.68867\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 359ms/step - accuracy: 0.9914 - loss: 0.0222 - val_accuracy: 0.4931 - val_loss: 0.8221\n",
            "Epoch 25/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.9934 - loss: 0.0188\n",
            "Epoch 25: val_accuracy did not improve from 0.68867\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 354ms/step - accuracy: 0.9934 - loss: 0.0188 - val_accuracy: 0.5634 - val_loss: 1.8378\n",
            "Epoch 26/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.9939 - loss: 0.0189\n",
            "Epoch 26: val_accuracy did not improve from 0.68867\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 354ms/step - accuracy: 0.9939 - loss: 0.0189 - val_accuracy: 0.5543 - val_loss: 1.6967\n",
            "Epoch 27/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.9948 - loss: 0.0148\n",
            "Epoch 27: val_accuracy did not improve from 0.68867\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 355ms/step - accuracy: 0.9948 - loss: 0.0148 - val_accuracy: 0.5672 - val_loss: 2.1266\n",
            "Epoch 28/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.9951 - loss: 0.0149\n",
            "Epoch 28: val_accuracy did not improve from 0.68867\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 359ms/step - accuracy: 0.9951 - loss: 0.0149 - val_accuracy: 0.5576 - val_loss: 1.3779\n",
            "Epoch 29/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.9934 - loss: 0.0173\n",
            "Epoch 29: val_accuracy did not improve from 0.68867\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 354ms/step - accuracy: 0.9934 - loss: 0.0173 - val_accuracy: 0.5662 - val_loss: 1.2844\n",
            "Epoch 30/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - accuracy: 0.9953 - loss: 0.0122\n",
            "Epoch 30: val_accuracy did not improve from 0.68867\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 352ms/step - accuracy: 0.9953 - loss: 0.0122 - val_accuracy: 0.6055 - val_loss: 1.5250\n",
            "Epoch 31/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step - accuracy: 0.9930 - loss: 0.0196\n",
            "Epoch 31: val_accuracy did not improve from 0.68867\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 360ms/step - accuracy: 0.9930 - loss: 0.0196 - val_accuracy: 0.5691 - val_loss: 2.3176\n",
            "Epoch 32/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.9948 - loss: 0.0129\n",
            "Epoch 32: val_accuracy did not improve from 0.68867\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 359ms/step - accuracy: 0.9948 - loss: 0.0129 - val_accuracy: 0.5725 - val_loss: 1.3716\n",
            "Epoch 33/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - accuracy: 0.9957 - loss: 0.0123\n",
            "Epoch 33: val_accuracy did not improve from 0.68867\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 363ms/step - accuracy: 0.9957 - loss: 0.0123 - val_accuracy: 0.5739 - val_loss: 3.2560\n",
            "Epoch 34/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - accuracy: 0.9940 - loss: 0.0165\n",
            "Epoch 34: val_accuracy did not improve from 0.68867\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 365ms/step - accuracy: 0.9940 - loss: 0.0165 - val_accuracy: 0.5787 - val_loss: 3.2834\n",
            "Epoch 35/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.9944 - loss: 0.0155\n",
            "Epoch 35: val_accuracy did not improve from 0.68867\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 355ms/step - accuracy: 0.9944 - loss: 0.0155 - val_accuracy: 0.5648 - val_loss: 1.8576\n",
            "Epoch 36/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.9947 - loss: 0.0130\n",
            "Epoch 36: val_accuracy did not improve from 0.68867\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 353ms/step - accuracy: 0.9947 - loss: 0.0130 - val_accuracy: 0.5619 - val_loss: 1.9169\n",
            "Epoch 37/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.9937 - loss: 0.0169\n",
            "Epoch 37: val_accuracy did not improve from 0.68867\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 353ms/step - accuracy: 0.9937 - loss: 0.0169 - val_accuracy: 0.5739 - val_loss: 2.0882\n",
            "Epoch 38/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.9952 - loss: 0.0136\n",
            "Epoch 38: val_accuracy did not improve from 0.68867\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 357ms/step - accuracy: 0.9952 - loss: 0.0136 - val_accuracy: 0.5801 - val_loss: 2.0448\n",
            "Epoch 39/50\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.9953 - loss: 0.0142\n",
            "Epoch 39: val_accuracy did not improve from 0.68867\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 357ms/step - accuracy: 0.9953 - loss: 0.0142 - val_accuracy: 0.5854 - val_loss: 2.6651\n",
            "Epoch 40/50\n",
            "\u001b[1m 68/147\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 326ms/step - accuracy: 0.9935 - loss: 0.0174"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def build_efficientnet():\n",
        "    inp = layers.Input(shape=(224,224,4))\n",
        "\n",
        "    rgb  = inp[..., :3]\n",
        "    mask = inp[..., 3:]\n",
        "\n",
        "    base = tf.keras.applications.EfficientNetB0(\n",
        "        include_top=False,\n",
        "        input_shape=(224,224,3),\n",
        "        weights=\"imagenet\"\n",
        "    )\n",
        "\n",
        "    x = base(rgb)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    m = layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\")(mask)\n",
        "    m = layers.GlobalAveragePooling2D()(m)\n",
        "\n",
        "    z = layers.Concatenate()([x, m])\n",
        "    z = layers.Dense(128, activation=\"relu\")(z)\n",
        "    z = layers.Dropout(0.3)(z)\n",
        "    out = layers.Dense(1, activation=\"sigmoid\")(z)\n",
        "\n",
        "    return models.Model(inp, out)"
      ],
      "metadata": {
        "id": "gAID4GaxZ3lX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_efficientnet()\n",
        "\n",
        "ckpt_path = \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/models/efficientnet_best(80-20).h5\"\n",
        "model.load_weights(ckpt_path)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "loss, acc = model.evaluate(test_ds)\n",
        "print(\" EfficientNet Test Accuracy:\", acc)\n",
        "print(\" EfficientNet Test Loss:\", loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyHU_ClrZcVx",
        "outputId": "1530d177-e050-4dd7-a0ae-b3b85be45f3a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 7s/step - accuracy: 0.6793 - loss: 1.4991\n",
            " EfficientNet Test Accuracy: 0.6836969256401062\n",
            " EfficientNet Test Loss: 1.4705231189727783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions\n",
        "y_probs = model.predict(test_ds)\n",
        "y_pred  = (y_probs > 0.5).astype(int).flatten()\n",
        "\n",
        "# Get true labels\n",
        "import numpy as np\n",
        "y_true = np.concatenate([y.numpy() for _, y in test_ds])\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, classification_report\n",
        "\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall    = recall_score(y_true, y_pred)\n",
        "f1        = f1_score(y_true, y_pred)\n",
        "auc       = roc_auc_score(y_true, y_probs)\n",
        "\n",
        "print(\"\\n Precision:\", precision)\n",
        "print(\" Recall:\", recall)\n",
        "print(\" F1-score:\", f1)\n",
        "print(\" ROC-AUC:\", auc)\n",
        "\n",
        "print(\"\\n Confusion Matrix:\")\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "print(\"\\n Full Classification Report:\")\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "id": "SIpM8Z3hb70h",
        "outputId": "44a477ff-42ca-4928-d370-6d2bc5238889",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m41/41\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 459ms/step\n",
            "\n",
            " Precision: 0.6638593014614813\n",
            " Recall: 0.9005376344086021\n",
            " F1-score: 0.7642948809354057\n",
            " ROC-AUC: 0.7248302718040621\n",
            "\n",
            " Confusion Matrix:\n",
            "[[ 893 1357]\n",
            " [ 296 2680]]\n",
            "\n",
            " Full Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.40      0.52      2250\n",
            "         1.0       0.66      0.90      0.76      2976\n",
            "\n",
            "    accuracy                           0.68      5226\n",
            "   macro avg       0.71      0.65      0.64      5226\n",
            "weighted avg       0.70      0.68      0.66      5226\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ew_lgSSgb7tB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_efficientnet()\n",
        "model.load_weights(ckpt_path)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "loss, acc = model.evaluate(test_ds)\n",
        "print(\"EfficientNet Test Loss:\", loss)\n",
        "print(\"EfficientNet Test Accuracy:\", acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHM_eWgT1T7s",
        "outputId": "2d0c449a-3fbe-4367-cd52-189f90f97d16"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 14s/step - accuracy: 0.7796 - loss: 1.1108\n",
            "EfficientNet Test Loss: 1.152380347251892\n",
            "EfficientNet Test Accuracy: 0.772675096988678\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_final[\"label\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWZE6QryYwaE",
        "outputId": "8217b8b2-57a5-40d6-d94e-76cc0d1143b8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "1.0    14961\n",
            "0.0    11325\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, models"
      ],
      "metadata": {
        "id": "Y6yvk49nafuL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_used = df_final.copy()\n",
        "df_used[\"label\"] = (df_used[\"class\"] == 2).astype(\"float32\")"
      ],
      "metadata": {
        "id": "deG13t3ibHkg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned = df_final.copy()\n",
        "\n",
        "# ensure everything is string\n",
        "df_cleaned[\"crop_path\"] = df_cleaned[\"crop_path\"].astype(str)\n",
        "df_cleaned[\"mask_path\"] = df_cleaned[\"mask_path\"].astype(str)\n",
        "\n",
        "# remove rows with 'nan', 'None', or 'NaN'\n",
        "df_cleaned = df_cleaned[\n",
        "    (df_cleaned[\"crop_path\"].str.contains(\"nan\") == False) &\n",
        "    (df_cleaned[\"crop_path\"].str.contains(\"None\") == False) &\n",
        "    (df_cleaned[\"mask_path\"].str.contains(\"nan\") == False) &\n",
        "    (df_cleaned[\"mask_path\"].str.contains(\"None\") == False)\n",
        "]\n",
        "\n",
        "import os\n",
        "df_cleaned = df_cleaned[df_cleaned[\"crop_path\"].apply(os.path.exists)]\n",
        "df_cleaned = df_cleaned[df_cleaned[\"mask_path\"].apply(os.path.exists)]"
      ],
      "metadata": {
        "id": "rmOECseLbuHo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned.head()\n",
        "len(df_cleaned)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAKRxOQFbwM-",
        "outputId": "2d0fa45c-7997-483d-e2f8-3478e66665ff"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26129"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = train_test_split(df_cleaned, test_size=0.10, stratify=df_cleaned[\"label\"], random_state=42)\n",
        "train_df, val_df  = train_test_split(train_df, test_size=0.10, stratify=train_df[\"label\"], random_state=42)"
      ],
      "metadata": {
        "id": "dilRd4sob7Id"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_paths = tf.constant(train_df[\"crop_path\"].tolist())\n",
        "train_labels = tf.constant(train_df[\"label\"].tolist(), dtype=tf.float32)\n",
        "\n",
        "val_paths = tf.constant(val_df[\"crop_path\"].tolist())\n",
        "val_labels = tf.constant(val_df[\"label\"].tolist(), dtype=tf.float32)\n",
        "\n",
        "test_paths = tf.constant(test_df[\"crop_path\"].tolist())\n",
        "test_labels = tf.constant(test_df[\"label\"].tolist(), dtype=tf.float32)"
      ],
      "metadata": {
        "id": "5n-O1UuYbdYC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 128\n",
        "AUTO = tf.data.AUTOTUNE\n",
        "\n",
        "def mask_from_crop(crop_path):\n",
        "    return tf.strings.regex_replace(crop_path, \"/crops/\", \"/masks/\")\n",
        "\n",
        "@tf.function\n",
        "def load_fused(crop_path, label):\n",
        "    mask_path = mask_from_crop(crop_path)\n",
        "\n",
        "    crop = tf.io.read_file(crop_path)\n",
        "    crop = tf.image.decode_png(crop, channels=3)\n",
        "    crop = tf.image.convert_image_dtype(crop, tf.float32)\n",
        "    crop = tf.image.resize(crop, IMG_SIZE)\n",
        "\n",
        "    mask = tf.io.read_file(mask_path)\n",
        "    mask = tf.image.decode_png(mask, channels=1)\n",
        "    mask = tf.image.convert_image_dtype(mask, tf.float32)\n",
        "    mask = tf.image.resize(mask, IMG_SIZE)\n",
        "\n",
        "    fused = tf.concat([crop, mask], axis=-1)\n",
        "    return fused, label\n",
        "\n",
        "@tf.function\n",
        "def augment(fused, label):\n",
        "    img = fused[..., :3]\n",
        "    msk = fused[..., 3:]\n",
        "\n",
        "    img = tf.image.random_flip_left_right(img)\n",
        "    img = tf.image.random_flip_up_down(img)\n",
        "    img = tf.image.random_brightness(img, 0.1)\n",
        "    img = tf.image.random_contrast(img, 0.9, 1.1)\n",
        "\n",
        "    fused = tf.concat([img, msk], axis=-1)\n",
        "    return fused, label"
      ],
      "metadata": {
        "id": "fEFKz5locBIC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_dataset(paths, labels, augment_flag=False):\n",
        "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
        "\n",
        "    if augment_flag:\n",
        "        ds = ds.shuffle(5000, seed=42)\n",
        "\n",
        "    ds = ds.map(load_fused, num_parallel_calls=AUTO)\n",
        "\n",
        "    if augment_flag:\n",
        "        ds = ds.map(augment, num_parallel_calls=AUTO)\n",
        "\n",
        "    # Cache results for extremely fast epoch 2+\n",
        "    ds = ds.cache(\"/content/cache_mitotic.tfcache\")\n",
        "\n",
        "    ds = ds.batch(BATCH_SIZE).prefetch(AUTO)\n",
        "    return ds"
      ],
      "metadata": {
        "id": "9EsnZRqhcCUN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = make_dataset(train_paths, train_labels, augment_flag=True)\n",
        "val_ds   = make_dataset(val_paths, val_labels, augment_flag=False)\n",
        "test_ds  = make_dataset(test_paths, test_labels, augment_flag=False)\n",
        "\n",
        "# sanity check\n",
        "for X, y in train_ds.take(1):\n",
        "    print(X.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zRD96wscEys",
        "outputId": "cd5cb60e-9c33-40d0-ee3a-a37e734c3537"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 224, 224, 4) (128,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_mobilenet():\n",
        "    inp = layers.Input(shape=(224,224,4))\n",
        "    rgb = inp[..., :3]\n",
        "    mask = inp[..., 3:]\n",
        "\n",
        "    base = tf.keras.applications.MobileNetV2(input_shape=(224,224,3), include_top=False, weights=\"imagenet\")\n",
        "    x = base(rgb)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    m = layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\")(mask)\n",
        "    m = layers.GlobalAveragePooling2D()(m)\n",
        "\n",
        "    z = layers.Concatenate()([x, m])\n",
        "    z = layers.Dense(128, activation=\"relu\")(z)\n",
        "    z = layers.Dropout(0.3)(z)\n",
        "    out = layers.Dense(1, activation=\"sigmoid\")(z)\n",
        "    return models.Model(inp, out)"
      ],
      "metadata": {
        "id": "brlMrIJscJVV"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -f /content/cache_mitotic.tfcache*"
      ],
      "metadata": {
        "id": "Tjr1pbF-dGYC"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = make_dataset(train_paths, train_labels, augment_flag=True)\n",
        "val_ds   = make_dataset(val_paths, val_labels)\n",
        "test_ds  = make_dataset(test_paths, test_labels)"
      ],
      "metadata": {
        "id": "N-HK7UkMdMM-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for X, y in train_ds.take(1):\n",
        "    print(X.shape, y.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWJrCnd7deWs",
        "outputId": "34edf3af-d8e8-4805-c07c-29598f18a219"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 224, 224, 4) (128,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VVLuLrSxEFm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SAVE_DIR = \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/models\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "model = build_mobilenet()\n",
        "# model = build_efficientnet()\n",
        "# model = build_resnet()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "ckpt_path = os.path.join(SAVE_DIR, \"mobilenet_best.h5\")\n",
        "\n",
        "ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
        "    ckpt_path,\n",
        "    save_best_only=True,\n",
        "    monitor=\"val_accuracy\",\n",
        "    mode=\"max\",\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=50,\n",
        "    callbacks=[ckpt]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "RMTEqsH6cT-S",
        "outputId": "b557f3f3-283d-4609-f2fb-663fff11c25e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x77fe06926480>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/weakref.py\", line 369, in remove\n",
            "    def remove(k, selfref=ref(self)):\n",
            "\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2206480690.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             ):\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    917\u001b[0m           )\n\u001b[1;32m    918\u001b[0m       )\n\u001b[0;32m--> 919\u001b[0;31m       return self._concrete_variable_creation_fn._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    920\u001b[0m           \u001b[0mfiltered_flat_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_variable_creation_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1689\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "def load_and_resize(path, channels):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_image(img, channels=channels, expand_animations=False)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    img = tf.image.resize(img, IMG_SIZE)\n",
        "    return img\n",
        "\n",
        "def fusion_loader(crop_path, mask_path, label):\n",
        "    crop = load_and_resize(crop_path, 3)\n",
        "    mask = load_and_resize(mask_path, 1)\n",
        "    fused = tf.concat([crop, mask], axis=-1)   # (224, 224, 4)\n",
        "    label = tf.cast(label, tf.float32)\n",
        "    return fused, label\n",
        "\n",
        "def make_dataset(df, batch=32, shuffle=False):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(\n",
        "        (df[\"crop_path\"], df[\"mask_path\"], df[\"class\"])\n",
        "    )\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(len(df))\n",
        "    ds = ds.map(fusion_loader, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    ds = ds.batch(batch).prefetch(tf.data.AUTOTUNE)\n",
        "    return ds"
      ],
      "metadata": {
        "id": "04US19XwbrsB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def augment(fused, label):\n",
        "    # Random flips\n",
        "    fused = tf.image.random_flip_left_right(fused)\n",
        "    fused = tf.image.random_flip_up_down(fused)\n",
        "\n",
        "    # Random rotation (0, 90, 180, 270 degrees)\n",
        "    k = tf.random.uniform(shape=(), minval=0, maxval=4, dtype=tf.int32)\n",
        "    fused = tf.image.rot90(fused, k)\n",
        "\n",
        "    # Random brightness for RGB channels (only apply to crop, not mask)\n",
        "    rgb = fused[..., :3]\n",
        "    mask = fused[..., 3:]\n",
        "\n",
        "    rgb = tf.image.random_brightness(rgb, max_delta=0.15)\n",
        "    rgb = tf.image.random_contrast(rgb, lower=0.8, upper=1.2)\n",
        "\n",
        "    # Optional slight Gaussian noise\n",
        "    noise = tf.random.normal(tf.shape(rgb), mean=0.0, stddev=0.03)\n",
        "    rgb = tf.clip_by_value(rgb + noise, 0.0, 1.0)\n",
        "\n",
        "    fused = tf.concat([rgb, mask], axis=-1)\n",
        "    return fused, label"
      ],
      "metadata": {
        "id": "kxthzhyub0lD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_dataset(df, batch=32, shuffle=False, augment_data=False):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(\n",
        "        (df[\"crop_path\"], df[\"mask_path\"], df[\"class\"])\n",
        "    )\n",
        "\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(len(df))\n",
        "\n",
        "    ds = ds.map(fusion_loader, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    if augment_data:\n",
        "        ds = ds.map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    ds = ds.batch(batch).prefetch(tf.data.AUTOTUNE)\n",
        "    return ds"
      ],
      "metadata": {
        "id": "fUuDSlG9cMh4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Requirements: pandas, sklearn\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
        "\n",
        "# df_final should be the dataframe you built with columns:\n",
        "# ['annotationID','slideID','x','y','class','filename','crop_path','mask_path','image_path']\n",
        "\n",
        "# 1) Deduplicate by annotationID (keep first)\n",
        "df = df_final.drop_duplicates(subset=[\"annotationID\"]).reset_index(drop=True)\n",
        "\n",
        "# 2) Drop rows with any missing paths (this prevents NoneType errors)\n",
        "df = df.dropna(subset=[\"crop_path\", \"mask_path\", \"image_path\"]).reset_index(drop=True)\n",
        "\n",
        "# 3) Ensure all files actually exist on disk (optional but recommended)\n",
        "def file_exists(p):\n",
        "    return (isinstance(p, str) and os.path.exists(p))\n",
        "exists_mask = df[\"crop_path\"].apply(file_exists) & df[\"mask_path\"].apply(file_exists) & df[\"image_path\"].apply(file_exists)\n",
        "df = df[exists_mask].reset_index(drop=True)\n",
        "\n",
        "print(\"After dedupe & file-check: total samples =\", len(df))\n",
        "\n",
        "# 4) Optional: convert class to int (0/1)\n",
        "df['class'] = df['class'].astype(int)  # or map your labels to 0/1\n",
        "\n",
        "# 5) Group-aware split by slideID to avoid leakage.\n",
        "#    We first split off the test set (e.g. 10%) by grouping on slideID\n",
        "gss = GroupShuffleSplit(n_splits=1, test_size=0.10, random_state=42)\n",
        "train_idx, test_idx = next(gss.split(df, groups=df['slideID']))\n",
        "df_temp = df.iloc[train_idx].reset_index(drop=True)\n",
        "df_test = df.iloc[test_idx].reset_index(drop=True)\n",
        "\n",
        "# Then split train -> train+val (e.g., 10% of remaining for val)\n",
        "gss2 = GroupShuffleSplit(n_splits=1, test_size=0.10, random_state=42)\n",
        "train_idx2, val_idx2 = next(gss2.split(df_temp, groups=df_temp['slideID']))\n",
        "df_train = df_temp.iloc[train_idx2].reset_index(drop=True)\n",
        "df_val   = df_temp.iloc[val_idx2].reset_index(drop=True)\n",
        "\n",
        "print(\"Train/Val/Test sizes:\", len(df_train), len(df_val), len(df_test))\n",
        "\n",
        "# 6) Create tf.data datasets from plain lists (no Series with None)\n",
        "IMG_SIZE = (224,224)\n",
        "\n",
        "def load_and_resize(path, channels):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_image(img, channels=channels, expand_animations=False)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    img = tf.image.resize(img, IMG_SIZE)\n",
        "    return img\n",
        "\n",
        "def fusion_loader(crop_path, mask_path, label):\n",
        "    crop = load_and_resize(crop_path, 3)\n",
        "    mask = load_and_resize(mask_path, 1)\n",
        "    fused = tf.concat([crop, mask], axis=-1)   # (H,W,4)\n",
        "    return fused, tf.cast(label, tf.float32)\n",
        "\n",
        "def make_dataset_from_df(df_in, batch=32, shuffle=False, augment_fn=None):\n",
        "    # use plain python lists (or numpy arrays)\n",
        "    crops = df_in['crop_path'].tolist()\n",
        "    masks = df_in['mask_path'].tolist()\n",
        "    labels = df_in['class'].tolist()\n",
        "    ds = tf.data.Dataset.from_tensor_slices((crops, masks, labels))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size=len(crops), seed=42)\n",
        "    ds = ds.map(lambda a,b,c: tf.py_function(\n",
        "                    func=lambda x,y,z: fusion_loader(x.numpy().decode(), y.numpy().decode(), int(z.numpy())),\n",
        "                    inp=[a,b,c],\n",
        "                    Tout=[tf.float32, tf.float32]),\n",
        "                num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    # fix static shapes (py_function loses shape)\n",
        "    def set_shapes(fused, lab):\n",
        "        fused.set_shape((IMG_SIZE[0], IMG_SIZE[1], 4))\n",
        "        lab.set_shape(())\n",
        "        return fused, lab\n",
        "    ds = ds.map(set_shapes, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    # optional augmentation\n",
        "    if augment_fn is not None:\n",
        "        ds = ds.map(lambda x,y: augment_fn(x,y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    ds = ds.batch(batch).prefetch(tf.data.AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "# Example augmentation function (simple)\n",
        "def augment(fused, label):\n",
        "    rgb = fused[..., :3]\n",
        "    mask = fused[..., 3:]\n",
        "    # flips\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        rgb = tf.image.flip_left_right(rgb); mask = tf.image.flip_left_right(mask)\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        rgb = tf.image.flip_up_down(rgb); mask = tf.image.flip_up_down(mask)\n",
        "    # small rotation\n",
        "    k = tf.random.uniform(shape=(), minval=0, maxval=4, dtype=tf.int32)\n",
        "    rgb = tf.image.rot90(rgb, k); mask = tf.image.rot90(mask, k)\n",
        "    # brightness/contrast\n",
        "    rgb = tf.image.random_brightness(rgb, 0.1)\n",
        "    rgb = tf.image.random_contrast(rgb, 0.9, 1.1)\n",
        "    fused = tf.concat([rgb, mask], axis=-1)\n",
        "    return fused, label\n",
        "\n",
        "# build datasets\n",
        "train_ds = make_dataset_from_df(df_train, batch=32, shuffle=True, augment_fn=augment)\n",
        "val_ds   = make_dataset_from_df(df_val, batch=32, shuffle=False, augment_fn=None)\n",
        "test_ds  = make_dataset_from_df(df_test, batch=32, shuffle=False, augment_fn=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzM_MA33svOV",
        "outputId": "2de67fc8-36a0-43b8-a320-e85297e1690d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After dedupe & file-check: total samples = 26129\n",
            "Train/Val/Test sizes: 22401 1855 1873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, Model\n",
        "import tensorflow as tf\n",
        "\n",
        "def build_mobilenet_fusion(input_shape=(224,224,4)):\n",
        "    inp = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Split inputs\n",
        "    rgb  = inp[..., :3]     # crop image\n",
        "    mask = inp[..., 3:]     # binary SAM mask\n",
        "\n",
        "    # ---------------------------\n",
        "    # Image encoder (MobileNetV2)\n",
        "    # ---------------------------\n",
        "    base = tf.keras.applications.MobileNetV2(\n",
        "        input_shape=(224,224,3),\n",
        "        include_top=False,\n",
        "        weights=\"imagenet\"\n",
        "    )\n",
        "    x = base(rgb)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # ---------------------------\n",
        "    # Mask encoder (small CNN)\n",
        "    # ---------------------------\n",
        "    m = layers.Conv2D(16, 3, padding=\"same\", activation=\"relu\")(mask)\n",
        "    m = layers.GlobalAveragePooling2D()(m)\n",
        "\n",
        "    # ---------------------------\n",
        "    # Fusion + classifier head\n",
        "    # ---------------------------\n",
        "    z = layers.Concatenate()([x, m])\n",
        "    z = layers.Dense(128, activation=\"relu\")(z)\n",
        "    z = layers.Dropout(0.3)(z)\n",
        "    out = layers.Dense(1, activation=\"sigmoid\")(z)\n",
        "\n",
        "    return Model(inp, out)\n",
        "\n",
        "model = build_mobilenet_fusion()\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "P12N5ALwtsZn",
        "outputId": "34cc450a-36d0-478e-ed94-49b52c716379"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " input_layer          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,            \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)         \u001b[38;5;34m4\u001b[0m)                                               \n",
              "\n",
              " get_item (\u001b[38;5;33mGetItem\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,            \u001b[38;5;34m0\u001b[0m  input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
              "                      \u001b[38;5;34m3\u001b[0m)                                               \n",
              "\n",
              " get_item_1           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,            \u001b[38;5;34m0\u001b[0m  input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
              " (\u001b[38;5;33mGetItem\u001b[0m)            \u001b[38;5;34m1\u001b[0m)                                               \n",
              "\n",
              " mobilenetv2_1.00_2  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,        \u001b[38;5;34m2,257,984\u001b[0m  get_item[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              " (\u001b[38;5;33mFunctional\u001b[0m)         \u001b[38;5;34m1280\u001b[0m)                                            \n",
              "\n",
              " conv2d (\u001b[38;5;33mConv2D\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,          \u001b[38;5;34m160\u001b[0m  get_item_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              "                      \u001b[38;5;34m16\u001b[0m)                                              \n",
              "\n",
              " global_average_poo  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                \u001b[38;5;34m0\u001b[0m  mobilenetv2_1.00 \n",
              " (\u001b[38;5;33mGlobalAveragePool\u001b[0m                                                   \n",
              "\n",
              " global_average_poo  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              " (\u001b[38;5;33mGlobalAveragePool\u001b[0m                                                   \n",
              "\n",
              " concatenate          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1296\u001b[0m)                \u001b[38;5;34m0\u001b[0m  global_average_p \n",
              " (\u001b[38;5;33mConcatenate\u001b[0m)                                       global_average_p \n",
              "\n",
              " dense (\u001b[38;5;33mDense\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)           \u001b[38;5;34m166,016\u001b[0m  concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
              "\n",
              " dropout (\u001b[38;5;33mDropout\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
              "\n",
              " dense_1 (\u001b[38;5;33mDense\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 \u001b[38;5;34m129\u001b[0m  dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n",
              "\n",
              " input_layer          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                                               \n",
              "\n",
              " get_item (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                                               \n",
              "\n",
              " get_item_1           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                                               \n",
              "\n",
              " mobilenetv2_1.00_2  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,        <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span>  get_item[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                                            \n",
              "\n",
              " conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,          <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>  get_item_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                                              \n",
              "\n",
              " global_average_poo  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  mobilenetv2_1.00 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool</span>                                                   \n",
              "\n",
              " global_average_poo  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool</span>                                                   \n",
              "\n",
              " concatenate          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1296</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  global_average_p \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                                       global_average_p \n",
              "\n",
              " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">166,016</span>  concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              "\n",
              " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
              "\n",
              " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span>  dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,424,289\u001b[0m (9.25 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,424,289</span> (9.25 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,390,177\u001b[0m (9.12 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,390,177</span> (9.12 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m34,112\u001b[0m (133.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,112</span> (133.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt_path = \"/content/mobilenet_fusion_best.h5\"\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        ckpt_path,\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_accuracy\",\n",
        "        mode=\"max\"\n",
        "    ),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\",\n",
        "        factor=0.5,\n",
        "        patience=4,\n",
        "        verbose=1\n",
        "    ),\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=8,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=50,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "1I70RfngtvuU",
        "outputId": "e2671c67-b1ca-45a4-8890-d1451ab76692"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m 44/701\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38:48\u001b[0m 4s/step - accuracy: 0.3988 - loss: -2.1831"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-643247376.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m ]\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             ):\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1689\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy('mixed_float16')"
      ],
      "metadata": {
        "id": "wtsZCUaAurMy"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (224, 224)   # Faster than 224, still good accuracy\n",
        "BATCH_SIZE = 64         # Double speed if GPU allows"
      ],
      "metadata": {
        "id": "OX5iUC-Suuss"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (224,224)\n",
        "\n",
        "def load_and_resize_tf(path, channels):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_png(img, channels=channels)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    img = tf.image.resize(img, IMG_SIZE)   #  MUST USE THIS\n",
        "    return img"
      ],
      "metadata": {
        "id": "tqX40V6GwNSi"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fusion_loader_tf(crop_path, mask_path, label):\n",
        "    crop = load_and_resize_tf(crop_path, 3)\n",
        "    mask = load_and_resize_tf(mask_path, 1)\n",
        "    fused = tf.concat([crop, mask], axis=-1)\n",
        "    return fused, tf.cast(label, tf.float32)"
      ],
      "metadata": {
        "id": "d0VBepdDwP_-"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def load_and_resize_tf(path, channels):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_png(img, channels=channels)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    img = tf.image.resize(img, IMG_SIZE)\n",
        "    return img\n",
        "\n",
        "def fusion_loader_tf(crop_path, mask_path, label):\n",
        "    crop = load_and_resize_tf(crop_path, 3)\n",
        "    mask = load_and_resize_tf(mask_path, 1)\n",
        "    fused = tf.concat([crop, mask], axis=-1)\n",
        "    return fused, tf.cast(label, tf.float32)"
      ],
      "metadata": {
        "id": "AUeJnGm6uwhG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_fast(fused, label):\n",
        "    rgb  = fused[..., :3]\n",
        "    mask = fused[..., 3:]\n",
        "\n",
        "    # Fast flips only\n",
        "    rgb  = tf.image.random_flip_left_right(rgb)\n",
        "    mask = tf.image.random_flip_left_right(mask)\n",
        "    rgb  = tf.image.random_flip_up_down(rgb)\n",
        "    mask = tf.image.random_flip_up_down(mask)\n",
        "\n",
        "    # Light jitter\n",
        "    rgb = tf.image.random_brightness(rgb, max_delta=0.10)\n",
        "    rgb = tf.image.random_contrast(rgb, 0.9, 1.1)\n",
        "\n",
        "    fused = tf.concat([rgb, mask], axis=-1)\n",
        "    return fused, label"
      ],
      "metadata": {
        "id": "PGsS2dSJuzaN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_dataset_fast(df, shuffle=False, augment=False):\n",
        "    crops  = df[\"crop_path\"].tolist()\n",
        "    masks  = df[\"mask_path\"].tolist()\n",
        "    labels = df[\"class\"].astype('float32').tolist()\n",
        "\n",
        "    ds = tf.data.Dataset.from_tensor_slices((crops, masks, labels))\n",
        "\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(len(df), reshuffle_each_iteration=True)\n",
        "\n",
        "    ds = ds.map(fusion_loader_tf, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    if augment:\n",
        "        ds = ds.map(augment_fast, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    ds = ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "    return ds"
      ],
      "metadata": {
        "id": "ojtigyVfu1ZZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "df = df_final.copy()\n",
        "\n",
        "# Fix annotationID being float  convert to int  string\n",
        "df[\"annotationID\"] = df[\"annotationID\"].astype(int).astype(str)\n",
        "\n",
        "# Force crop/mask paths into PURE strings\n",
        "df[\"crop_path\"] = df[\"crop_path\"].astype(str)\n",
        "df[\"mask_path\"] = df[\"mask_path\"].astype(str)\n",
        "df[\"image_path\"] = df[\"image_path\"].astype(str)\n",
        "\n",
        "# Remove rows containing 'nan' or 'None' in paths\n",
        "df = df[\n",
        "    (~df[\"crop_path\"].str.contains(\"nan\")) &\n",
        "    (~df[\"mask_path\"].str.contains(\"nan\")) &\n",
        "    (~df[\"image_path\"].str.contains(\"nan\"))\n",
        "]\n",
        "\n",
        "# Remove rows where file does not exist\n",
        "df = df[df[\"crop_path\"].apply(os.path.exists)]\n",
        "df = df[df[\"mask_path\"].apply(os.path.exists)]\n",
        "df = df[df[\"image_path\"].apply(os.path.exists)]\n",
        "\n",
        "# MOST IMPORTANT: Deduplicate annotationID\n",
        "df = df.drop_duplicates(subset=\"annotationID\").reset_index(drop=True)\n",
        "\n",
        "print(\"Cleaned rows:\", len(df))\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "kPBpE21mu4OP",
        "outputId": "c032f0fb-4d80-433b-e5f2-7950a38fcefd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned rows: 26129\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  annotationID  slideID       x       y  class  filename  \\\n",
              "0            1        1  4361.0   371.0      2  001.tiff   \n",
              "1            2        1   781.0   897.0      2  001.tiff   \n",
              "2            3        1   295.0  4069.0      2  001.tiff   \n",
              "3            4        1  6697.5   731.5      0  001.tiff   \n",
              "4            5        2  1897.0   344.0      2  002.tiff   \n",
              "\n",
              "                                           crop_path  \\\n",
              "0  /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/1...   \n",
              "1  /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/2...   \n",
              "2  /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/3...   \n",
              "3  /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/4...   \n",
              "4  /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/5...   \n",
              "\n",
              "                                           mask_path  \\\n",
              "0  /content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/1...   \n",
              "1  /content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/2...   \n",
              "2  /content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/3...   \n",
              "3  /content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/4...   \n",
              "4  /content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/5...   \n",
              "\n",
              "                                          image_path  \n",
              "0  /content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...  \n",
              "1  /content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...  \n",
              "2  /content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...  \n",
              "3  /content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...  \n",
              "4  /content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ab34ce3e-a9be-43f0-a729-afcf0b2111bb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>annotationID</th>\n",
              "      <th>slideID</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>class</th>\n",
              "      <th>filename</th>\n",
              "      <th>crop_path</th>\n",
              "      <th>mask_path</th>\n",
              "      <th>image_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4361.0</td>\n",
              "      <td>371.0</td>\n",
              "      <td>2</td>\n",
              "      <td>001.tiff</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/1...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/1...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>781.0</td>\n",
              "      <td>897.0</td>\n",
              "      <td>2</td>\n",
              "      <td>001.tiff</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/2...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/2...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>295.0</td>\n",
              "      <td>4069.0</td>\n",
              "      <td>2</td>\n",
              "      <td>001.tiff</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/3...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/3...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>6697.5</td>\n",
              "      <td>731.5</td>\n",
              "      <td>0</td>\n",
              "      <td>001.tiff</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/4...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/4...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1897.0</td>\n",
              "      <td>344.0</td>\n",
              "      <td>2</td>\n",
              "      <td>002.tiff</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/5...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/5...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab34ce3e-a9be-43f0-a729-afcf0b2111bb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ab34ce3e-a9be-43f0-a729-afcf0b2111bb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ab34ce3e-a9be-43f0-a729-afcf0b2111bb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-03fbb670-0446-4b2f-8575-9b0d368ea699\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-03fbb670-0446-4b2f-8575-9b0d368ea699')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-03fbb670-0446-4b2f-8575-9b0d368ea699 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 26129,\n  \"fields\": [\n    {\n      \"column\": \"annotationID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26129,\n        \"samples\": [\n          \"21922\",\n          \"6736\",\n          \"11502\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"slideID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 132,\n        \"min\": 1,\n        \"max\": 553,\n        \"num_unique_values\": 500,\n        \"samples\": [\n          415,\n          76,\n          428\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1904.6966482626876,\n        \"min\": -2.0,\n        \"max\": 7208.0,\n        \"num_unique_values\": 8509,\n        \"samples\": [\n          2168.0,\n          366.5,\n          6884.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1426.339862436133,\n        \"min\": -5.0,\n        \"max\": 5404.0,\n        \"num_unique_values\": 6898,\n        \"samples\": [\n          3007.0,\n          3291.0,\n          4508.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"415.tiff\",\n          \"076.tiff\",\n          \"428.tiff\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"crop_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26129,\n        \"samples\": [\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/21922.png\",\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/6736.png\",\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/11502.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mask_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26129,\n        \"samples\": [\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/21922.png\",\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/6736.png\",\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/11502.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_path\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/415.tiff\",\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/076.tiff\",\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/428.tiff\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, Model\n",
        "\n",
        "def build_mobilenet_fusion(input_shape=(160,160,4)):\n",
        "    inp = layers.Input(shape=input_shape)\n",
        "\n",
        "    rgb  = inp[..., :3]\n",
        "    mask = inp[..., 3:]\n",
        "\n",
        "    base = tf.keras.applications.MobileNetV2(\n",
        "        input_shape=(160,160,3),\n",
        "        include_top=False,\n",
        "        weights=\"imagenet\",\n",
        "        alpha=0.35   # lighter model = faster\n",
        "    )\n",
        "\n",
        "    x = base(rgb)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    m = layers.Conv2D(16, 3, padding=\"same\", activation=\"relu\")(mask)\n",
        "    m = layers.GlobalAveragePooling2D()(m)\n",
        "\n",
        "    z = layers.Concatenate()([x, m])\n",
        "    z = layers.Dense(128, activation=\"relu\")(z)\n",
        "    z = layers.Dropout(0.3)(z)\n",
        "\n",
        "    out = layers.Dense(1, activation=\"sigmoid\", dtype='float32')(z)\n",
        "\n",
        "    return Model(inp, out)\n",
        "\n",
        "model = build_mobilenet_fusion()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqEMKRwBvN3N",
        "outputId": "a8503f30-9229-40bc-e2da-98bcb192b0d0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_0.35_160_no_top.h5\n",
            "\u001b[1m2019640/2019640\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_dir = \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/models\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "ckpt_path = f\"{save_dir}/mobilenet_fast_best.h5\""
      ],
      "metadata": {
        "id": "UyF1aT91vTef"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.image.resize(img, IMG_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "0vqHUZCJvx1r",
        "outputId": "7e40e83b-7669-409f-e4ff-3a53cb98bc52"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'img' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3486466254.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'img' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 64"
      ],
      "metadata": {
        "id": "D21xJWCXw1DF"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_resize_tf(path, channels):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_png(img, channels=channels)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    img = tf.image.resize(img, IMG_SIZE)   # <-- 224x224 here\n",
        "    return img\n",
        "\n",
        "def fusion_loader_tf(crop_path, mask_path, label):\n",
        "    crop = load_and_resize_tf(crop_path, 3)\n",
        "    mask = load_and_resize_tf(mask_path, 1)\n",
        "    fused = tf.concat([crop, mask], axis=-1)  # 4 channels\n",
        "    return fused, tf.cast(label, tf.float32)"
      ],
      "metadata": {
        "id": "j-8txceVw2jo"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_fast(fused, label):\n",
        "    rgb  = fused[..., :3]\n",
        "    mask = fused[..., 3:]\n",
        "\n",
        "    # Flips\n",
        "    rgb = tf.image.random_flip_left_right(rgb)\n",
        "    mask = tf.image.random_flip_left_right(mask)\n",
        "\n",
        "    rgb = tf.image.random_flip_up_down(rgb)\n",
        "    mask = tf.image.random_flip_up_down(mask)\n",
        "\n",
        "    # Light color jitter\n",
        "    rgb = tf.image.random_brightness(rgb, 0.1)\n",
        "    rgb = tf.image.random_contrast(rgb, 0.9, 1.1)\n",
        "\n",
        "    fused = tf.concat([rgb, mask], axis=-1)\n",
        "    return fused, label"
      ],
      "metadata": {
        "id": "yUgpCtmCw4jf"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_dataset_fast(df, shuffle=False, augment=False):\n",
        "    crops  = df[\"crop_path\"].tolist()\n",
        "    masks  = df[\"mask_path\"].tolist()\n",
        "    labels = df[\"class\"].astype('float32').tolist()\n",
        "\n",
        "    ds = tf.data.Dataset.from_tensor_slices((crops, masks, labels))\n",
        "\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(len(df), seed=42, reshuffle_each_iteration=True)\n",
        "\n",
        "    ds = ds.map(fusion_loader_tf, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    if augment:\n",
        "        ds = ds.map(augment_fast, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    ds = ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "    return ds"
      ],
      "metadata": {
        "id": "9p-t4yIyw6rt"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "def load_and_resize_tf(path, channels):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_png(img, channels=channels)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    img = tf.image.resize(img, IMG_SIZE)     # ALWAYS correct size\n",
        "    return img\n",
        "\n",
        "def fusion_loader_tf(crop_path, mask_path, label):\n",
        "    crop = load_and_resize_tf(crop_path, 3)\n",
        "    mask = load_and_resize_tf(mask_path, 1)\n",
        "    fused = tf.concat([crop, mask], axis=-1) # ALWAYS shape (224,224,4)\n",
        "    return fused, tf.cast(label, tf.float32)"
      ],
      "metadata": {
        "id": "L4LMSqQRxKl5"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "from tensorflow.keras import layers, Model\n",
        "\n",
        "def build_mobilenet_fusion(input_shape=(224,224,4)):\n",
        "    inp = layers.Input(shape=input_shape)\n",
        "\n",
        "    rgb  = inp[..., :3]\n",
        "    mask = inp[..., 3:]\n",
        "\n",
        "    base = tf.keras.applications.MobileNetV2(\n",
        "        input_shape=(224,224,3),\n",
        "        include_top=False,\n",
        "        weights=\"imagenet\",\n",
        "        alpha=0.35\n",
        "    )\n",
        "    x = base(rgb)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    m = layers.Conv2D(16, 3, padding=\"same\", activation=\"relu\")(mask)\n",
        "    m = layers.GlobalAveragePooling2D()(m)\n",
        "\n",
        "    z = layers.Concatenate()([x, m])\n",
        "    z = layers.Dense(128, activation=\"relu\")(z)\n",
        "    z = layers.Dropout(0.3)(z)\n",
        "\n",
        "    out = layers.Dense(1, activation=\"sigmoid\", dtype='float32')(z)\n",
        "\n",
        "    return Model(inp, out)\n",
        "\n",
        "model = build_mobilenet_fusion()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "9_X4P95XxEN3"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_dir = \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/models\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "ckpt_path = f\"{save_dir}/mobilenet224_best.h5\""
      ],
      "metadata": {
        "id": "sVUDK7JsxGPX"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        ckpt_path,\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_accuracy\",\n",
        "        mode=\"max\",\n",
        "        verbose=1\n",
        "    ),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\",\n",
        "        factor=0.5,\n",
        "        patience=3,\n",
        "        verbose=1\n",
        "    ),\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=6,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=50,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "3tznV9-NvXMl",
        "outputId": "12df1ccb-f32e-4ec5-be9e-eee09f28ee3d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m 57/701\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m36:30\u001b[0m 3s/step - accuracy: 0.4115 - loss: -2.6054"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1084763099.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m ]\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             ):\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1689\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = make_dataset(df_train, shuffle=True, augment_data=True)\n",
        "val_ds   = make_dataset(df_val, augment_data=False)\n",
        "test_ds  = make_dataset(df_test, augment_data=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "3GmcEqHecPRJ",
        "outputId": "2036e4c9-bb40-40b8-f80d-9f6d1f7612ac"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-477914198.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_ds\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_ds\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_train, df_test = train_test_split(df_final, test_size=0.10, random_state=42)\n",
        "df_train, df_val  = train_test_split(df_train, test_size=0.10, random_state=42)\n",
        "\n",
        "train_ds = make_dataset(df_train, shuffle=True, batch=32)\n",
        "val_ds   = make_dataset(df_val, batch=32)\n",
        "test_ds  = make_dataset(df_test, batch=32)\n",
        "\n",
        "len(df_train), len(df_val), len(df_test)"
      ],
      "metadata": {
        "id": "g_5Wl7GgcXUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "i8g92dWVcIeN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qx1izTe1EWWG"
      },
      "outputs": [],
      "source": [
        "df = df_clean.copy()  # from previous step\n",
        "\n",
        "images_dir = \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/images\"\n",
        "crops_dir  = \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "X2_vN9IyFVD8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs(crops_dir, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1ewai7zrFXe3"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "CROP_SIZE = 128\n",
        "HALF = CROP_SIZE // 2\n",
        "\n",
        "def safe_crop(img, x, y, crop_size=128):\n",
        "    h, w = img.shape[:2]\n",
        "\n",
        "    x1 = max(0, x - HALF)\n",
        "    y1 = max(0, y - HALF)\n",
        "    x2 = min(w, x + HALF)\n",
        "    y2 = min(h, y + HALF)\n",
        "\n",
        "    crop = img[y1:y2, x1:x2]\n",
        "\n",
        "    # If crop is smaller at boundaries  pad to 128px\n",
        "    if crop.shape[0] != CROP_SIZE or crop.shape[1] != CROP_SIZE:\n",
        "        pad_y = CROP_SIZE - crop.shape[0]\n",
        "        pad_x = CROP_SIZE - crop.shape[1]\n",
        "        crop = np.pad(crop, ((0,pad_y),(0,pad_x),(0,0)), mode='constant', constant_values=0)\n",
        "\n",
        "    return crop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUJxsj0TFnGk",
        "outputId": "e3db54cc-3016-445e-f451-5fe7e4f4fd89"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|         | 30/503 [01:38<18:54,  2.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Could not open: /content/drive/MyDrive/MIDOGPP/MIDOGpp/images/030.tiff\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|         | 34/503 [01:45<13:21,  1.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Could not open: /content/drive/MyDrive/MIDOGPP/MIDOGpp/images/034.tiff\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 63%|   | 315/503 [17:03<06:56,  2.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Could not open: /content/drive/MyDrive/MIDOGPP/MIDOGpp/images/365.tiff\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 503/503 [27:26<00:00,  3.27s/it]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "CROP_SIZE = 128\n",
        "HALF = CROP_SIZE // 2\n",
        "\n",
        "def safe_crop(img, x, y):\n",
        "    h, w = img.shape[:2]\n",
        "\n",
        "    x1 = max(0, x - HALF)\n",
        "    y1 = max(0, y - HALF)\n",
        "    x2 = min(w, x + HALF)\n",
        "    y2 = min(h, y + HALF)\n",
        "\n",
        "    crop = img[y1:y2, x1:x2]\n",
        "\n",
        "    if crop.shape[0] != CROP_SIZE or crop.shape[1] != CROP_SIZE:\n",
        "        pad_y = CROP_SIZE - crop.shape[0]\n",
        "        pad_x = CROP_SIZE - crop.shape[1]\n",
        "        crop = np.pad(crop, ((0, pad_y), (0, pad_x), (0, 0)),\n",
        "                      mode='constant', constant_values=0)\n",
        "\n",
        "    return crop\n",
        "\n",
        "\n",
        "images_dir = \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/images\"\n",
        "crops_dir  = \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops\"\n",
        "os.makedirs(crops_dir, exist_ok=True)\n",
        "\n",
        "# GROUP BY SLIDE\n",
        "grouped = df.groupby(\"filename\")\n",
        "\n",
        "for slide_name, group in tqdm(grouped, total=len(grouped)):\n",
        "    slide_path = f\"{images_dir}/{slide_name}\"\n",
        "\n",
        "    img = cv2.imread(slide_path)\n",
        "    if img is None:\n",
        "        print(\"Could not open:\", slide_path)\n",
        "        continue\n",
        "\n",
        "    # Process all annotations belonging to THIS slide\n",
        "    for _, row in group.iterrows():\n",
        "        x = int(row[\"x\"])\n",
        "        y = int(row[\"y\"])\n",
        "        ann = int(row[\"annotationID\"])\n",
        "\n",
        "        crop = safe_crop(img, x, y)\n",
        "        crop_path = f\"{crops_dir}/{ann}.png\"\n",
        "        cv2.imwrite(crop_path, crop)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--kQppDQFtpB",
        "outputId": "57e2e082-d3b1-47e4-e35a-9d7bfb9c82ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/facebookresearch/segment-anything.git\n",
            "  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-787nk8ft\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-787nk8ft\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n",
            "    requirement_set = resolver.resolve(\n",
            "                      ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 76, in resolve\n",
            "    collected = self.factory.collect_root_requirements(root_reqs)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 538, in collect_root_requirements\n",
            "    reqs = list(\n",
            "           ^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 494, in _make_requirements_from_install_req\n",
            "    cand = self._make_base_candidate_from_link(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 231, in _make_base_candidate_from_link\n",
            "    self._link_candidate_cache[link] = LinkCandidate(\n",
            "                                       ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 303, in __init__\n",
            "    super().__init__(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 158, in __init__\n",
            "    self.dist = self._prepare()\n",
            "                ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 235, in _prepare\n",
            "    dist = self._prepare_distribution()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 314, in _prepare_distribution\n",
            "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/operations/prepare.py\", line 527, in prepare_linked_requirement\n",
            "    return self._prepare_linked_requirement(req, parallel_builds)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/operations/prepare.py\", line 598, in _prepare_linked_requirement\n",
            "    local_file = unpack_url(\n",
            "                 ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/operations/prepare.py\", line 159, in unpack_url\n",
            "    unpack_vcs_link(link, location, verbosity=verbosity)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/operations/prepare.py\", line 81, in unpack_vcs_link\n",
            "    vcs_backend.unpack(location, url=hide_url(link.url), verbosity=verbosity)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/vcs/versioncontrol.py\", line 589, in unpack\n",
            "    self.obtain(location, url=url, verbosity=verbosity)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/vcs/versioncontrol.py\", line 502, in obtain\n",
            "    self.fetch_new(dest, url, rev_options, verbosity=verbosity)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/vcs/git.py\", line 277, in fetch_new\n",
            "    self.run_command(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/vcs/versioncontrol.py\", line 631, in run_command\n",
            "    return call_subprocess(\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/utils/subprocess.py\", line 151, in call_subprocess\n",
            "    line: str = proc.stdout.readline()\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1586, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1682, in _log\n",
            "    record = self.makeRecord(self.name, level, fn, lno, msg, args,\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1651, in makeRecord\n",
            "    rv = _logRecordFactory(name, level, fn, lno, msg, args, exc_info, func,\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 332, in __init__\n",
            "    self.filename = os.path.basename(pathname)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen posixpath>\", line 173, in basename\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/facebookresearch/segment-anything.git\n",
        "!pip install opencv-python matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNKumDcFOAbi",
        "outputId": "3dde3327-2cb9-461e-aed0-30ee2b0176a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-11-30 19:49:08--  https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 18.173.132.81, 18.173.132.13, 18.173.132.6, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|18.173.132.81|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2564550879 (2.4G) [binary/octet-stream]\n",
            "Saving to: sam_vit_h.pth\n",
            "\n",
            "sam_vit_h.pth       100%[===================>]   2.39G   133MB/s    in 13s     \n",
            "\n",
            "2025-11-30 19:49:21 (187 MB/s) - sam_vit_h.pth saved [2564550879/2564550879]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O sam_vit_h.pth https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "CdXjFh6YOE__",
        "outputId": "414fcc42-61ec-4fd8-bd94-08243981d345"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'segment_anything'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3506256061.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msegment_anything\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msam_model_registry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSamPredictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msam_checkpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"sam_vit_h.pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"vit_h\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'segment_anything'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from segment_anything import sam_model_registry, SamPredictor\n",
        "\n",
        "sam_checkpoint = \"sam_vit_h.pth\"\n",
        "model_type = \"vit_h\"\n",
        "\n",
        "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
        "sam.to(\"cuda\")\n",
        "predictor = SamPredictor(sam)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kg5GTluvOKPZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "def get_sam_mask(crop):\n",
        "    crop_rgb = cv2.cvtColor(crop, cv2.COLOR_BGR2RGB)\n",
        "    predictor.set_image(crop_rgb)\n",
        "\n",
        "    input_point = np.array([[64, 64]])   # center point\n",
        "    input_label = np.array([1])          # foreground\n",
        "\n",
        "    masks, scores, _ = predictor.predict(\n",
        "        point_coords=input_point,\n",
        "        point_labels=input_label,\n",
        "        multimask_output=False,\n",
        "    )\n",
        "\n",
        "    mask = masks[0].astype(np.uint8) * 255\n",
        "    return mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWbH-oixOUXN"
      },
      "outputs": [],
      "source": [
        "masks_dir = \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks\"\n",
        "os.makedirs(masks_dir, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhsO1BbkPL2S"
      },
      "outputs": [],
      "source": [
        "df_clean[\"crop_path\"] = df_clean[\"annotationID\"].apply(\n",
        "    lambda x: f\"{crops_dir}/{x}.png\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "tNEmFetTSFVF",
        "outputId": "ca9ac210-869d-4784-e5e8-8586a8165fe3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/62614 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'predictor' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3757887308.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sam_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mmask_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{masks_dir}/{ann}.png\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-71552212.py\u001b[0m in \u001b[0;36mget_sam_mask\u001b[0;34m(crop)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_sam_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcrop_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop_rgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0minput_point\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# center point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'predictor' is not defined"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import cv2\n",
        "\n",
        "for idx, row in tqdm(df_clean.iterrows(), total=len(df_clean)):\n",
        "    crop_path = row[\"crop_path\"]\n",
        "    ann = int(row[\"annotationID\"])\n",
        "\n",
        "    crop = cv2.imread(crop_path)\n",
        "    if crop is None:\n",
        "        continue\n",
        "\n",
        "    mask = get_sam_mask(crop)\n",
        "    mask_path = f\"{masks_dir}/{ann}.png\"\n",
        "    cv2.imwrite(mask_path, mask)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "OYUqWxCsTgtG",
        "outputId": "236d60b9-0f29-49e8-ff08-e85bfd94b775"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'mobile_sam'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1122816232.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmobile_sam\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msam_model_registry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSamPredictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcheckpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/mobile_sam.pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mobile_sam'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from mobile_sam import sam_model_registry, SamPredictor\n",
        "import torch\n",
        "\n",
        "checkpoint_path = \"/content/mobile_sam.pt\"\n",
        "\n",
        "sam = sam_model_registry[\"vit_t\"](checkpoint=checkpoint_path)\n",
        "sam.to(\"cuda\")\n",
        "sam.half()   # FP16 for speed\n",
        "predictor = SamPredictor(sam)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "QU1zcCpnR_O2",
        "outputId": "48013311-1978-4149-f81e-bb5fa7a7527e"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'mobile_sam'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-817761936.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmobile_sam\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msam_model_registry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSamPredictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mobile_sam'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from mobile_sam import sam_model_registry, SamPredictor\n",
        "import torch\n",
        "\n",
        "# Load MobileSAM (very fast)\n",
        "sam = sam_model_registry[\"vit_t\"](checkpoint=\"mobile_sam.pt\")\n",
        "sam.to(\"cuda\")\n",
        "sam.half()  # fp16 for extra speed\n",
        "\n",
        "predictor = SamPredictor(sam)\n",
        "\n",
        "def get_mask(crop):\n",
        "    crop_rgb = cv2.cvtColor(crop, cv2.COLOR_BGR2RGB)\n",
        "    predictor.set_image(crop_rgb)\n",
        "\n",
        "    input_point = np.array([[64, 64]])\n",
        "    input_label = np.array([1])\n",
        "\n",
        "    masks, _, _ = predictor.predict(\n",
        "        point_coords=input_point,\n",
        "        point_labels=input_label,\n",
        "        multimask_output=False\n",
        "    )\n",
        "\n",
        "    return (masks[0] * 255).astype(np.uint8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "dl0SJ4O3Ro8L",
        "outputId": "85e7e462-9afb-4f09-b619-f9ae7c597ec9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/62614 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'predictor' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3976172696.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sam_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mmask_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{masks_dir}/{row['annotationID']}.png\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-71552212.py\u001b[0m in \u001b[0;36mget_sam_mask\u001b[0;34m(crop)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_sam_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcrop_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop_rgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0minput_point\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# center point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'predictor' is not defined"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import cv2\n",
        "\n",
        "for idx, row in tqdm(df_clean.iterrows(), total=len(df_clean)):\n",
        "    crop_path = row[\"crop_path\"]\n",
        "\n",
        "    crop = cv2.imread(crop_path)\n",
        "    if crop is None:\n",
        "        print(\"Could not read:\", crop_path)\n",
        "        continue\n",
        "\n",
        "    mask = get_sam_mask(crop)\n",
        "    mask_path = f\"{masks_dir}/{row['annotationID']}.png\"\n",
        "    cv2.imwrite(mask_path, mask)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jf20Xq0zRozE",
        "outputId": "b4f3ece4-6096-4439-f915-6a19e7f45136"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/ChaoningZhang/MobileSAM.git\n",
            "  Cloning https://github.com/ChaoningZhang/MobileSAM.git to /tmp/pip-req-build-onvazdp3\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/ChaoningZhang/MobileSAM.git /tmp/pip-req-build-onvazdp3\n",
            "  Resolved https://github.com/ChaoningZhang/MobileSAM.git to commit 34bbbfdface3c18e5221aa7de6032d7220c6c6a1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mobile_sam\n",
            "  Building wheel for mobile_sam (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mobile_sam: filename=mobile_sam-1.0-py3-none-any.whl size=42431 sha256=68e80e006bf089dbd81365a685feee7f810ea32ff7e9d6f58828ccc203764b7c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zfms5jd2/wheels/5f/88/d6/5c0b5d4d64a06e19190d50269d8725c8aeadb128c966801af5\n",
            "Successfully built mobile_sam\n",
            "Installing collected packages: mobile_sam\n",
            "Successfully installed mobile_sam-1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/ChaoningZhang/MobileSAM.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvAOhLv9UR8z",
        "outputId": "53840589-a362-4871-c899-c247882cfdf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-11-30 19:55:18--  https://github.com/ChaoningZhang/MobileSAM/releases/download/v1.0/mobile_sam.pt\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-11-30 19:55:18 ERROR 404: Not Found.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O mobile_sam.pt https://github.com/ChaoningZhang/MobileSAM/releases/download/v1.0/mobile_sam.pt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1Z--BFFUckr",
        "outputId": "f2604ea9-65c3-45b5-bbdb-786d87ae46a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/facebookresearch/segment-anything.git\n",
            "  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-5001plrj\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-5001plrj\n",
            "  Resolved https://github.com/facebookresearch/segment-anything.git to commit dca509fe793f601edb92606367a655c15ac00fdf\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: segment_anything\n",
            "  Building wheel for segment_anything (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segment_anything: filename=segment_anything-1.0-py3-none-any.whl size=36592 sha256=85db61d8e0137c4f0c878a8cf326ba57ae8ae687f0f0c29f8932fe8a45c9faef\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1f0on599/wheels/29/82/ff/04e2be9805a1cb48bec0b85b5a6da6b63f647645750a0e42d4\n",
            "Successfully built segment_anything\n",
            "Installing collected packages: segment_anything\n",
            "Successfully installed segment_anything-1.0\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/facebookresearch/segment-anything.git\n",
        "!pip install opencv-python matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rPCQvVaUdmn",
        "outputId": "253602b9-8a8c-4320-80eb-b463c69f3cb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-11-30 19:54:31--  https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.35.37.84, 13.35.37.90, 13.35.37.111, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.35.37.84|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 375042383 (358M) [binary/octet-stream]\n",
            "Saving to: sam_vit_b.pth\n",
            "\n",
            "sam_vit_b.pth       100%[===================>] 357.67M   306MB/s    in 1.2s    \n",
            "\n",
            "2025-11-30 19:54:32 (306 MB/s) - sam_vit_b.pth saved [375042383/375042383]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O sam_vit_b.pth https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlFJkDWpUhSi",
        "outputId": "fcf220bf-3e34-4af7-84b5-99a1351bf7b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 358M Apr  4  2023 sam_vit_b.pth\n"
          ]
        }
      ],
      "source": [
        "!ls -lh sam_vit_b.pth\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLOzNSjGUl5b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from segment_anything import sam_model_registry, SamPredictor\n",
        "\n",
        "device = \"cuda\"\n",
        "\n",
        "sam_checkpoint = \"sam_vit_b.pth\"\n",
        "model_type = \"vit_b\"\n",
        "\n",
        "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
        "sam.to(device)\n",
        "\n",
        "predictor = SamPredictor(sam)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41r1cesJUqGW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def get_sam_mask(crop):\n",
        "    crop_rgb = cv2.cvtColor(crop, cv2.COLOR_BGR2RGB)\n",
        "    predictor.set_image(crop_rgb)\n",
        "\n",
        "    input_point = np.array([[64, 64]])\n",
        "    input_label = np.array([1])\n",
        "\n",
        "    masks, scores, _ = predictor.predict(\n",
        "        point_coords=input_point,\n",
        "        point_labels=input_label,\n",
        "        multimask_output=False\n",
        "    )\n",
        "\n",
        "    mask = (masks[0] * 255).astype(np.uint8)\n",
        "    return mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_s9HCBlVkhT"
      },
      "outputs": [],
      "source": [
        "df_clean[\"crop_path\"] = df_clean[\"annotationID\"].apply(\n",
        "    lambda x: f\"{crops_dir}/{x}.png\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SGrvKDUVcEp",
        "outputId": "61de3902-ab76-47f0-b02c-635b46f1cefc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|         | 1559/62614 [10:59<6:11:19,  2.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/630.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/630.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/631.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/631.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/632.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/632.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/633.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/633.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/633.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/634.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/634.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/635.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/635.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/635.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/636.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/636.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/636.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/637.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/637.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/638.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/638.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/639.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/639.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/640.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/640.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/640.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/641.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/641.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/642.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/642.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/643.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/643.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/644.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/644.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/645.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/645.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/646.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/646.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/646.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/647.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/647.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/648.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/648.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/649.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/649.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/650.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/650.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/650.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/651.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/651.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/651.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/652.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/652.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/652.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/653.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/653.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/653.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/654.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/654.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/654.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/655.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/655.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/655.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/656.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/656.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/656.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/657.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/657.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/657.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/658.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/658.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/658.png\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|         | 1764/62614 [11:53<4:39:19,  3.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/712.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/712.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/713.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/713.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/714.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/714.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/715.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/715.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/716.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/716.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/717.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/717.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/718.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/718.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/719.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/719.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/720.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/720.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/720.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/721.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/721.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/722.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/722.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/723.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/723.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/724.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/724.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/725.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/725.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/726.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/726.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/727.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/727.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/728.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/728.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/729.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/729.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/730.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/730.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/730.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/731.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/731.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/732.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/732.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/732.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/733.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/733.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/733.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/734.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/734.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/735.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/735.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/735.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/736.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/736.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/736.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/737.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/737.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/738.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/738.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/739.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/739.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/740.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/740.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/741.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/741.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/742.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/742.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/742.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/743.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/743.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/743.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/744.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/744.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/745.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/745.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/745.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/746.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/746.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/747.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/747.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/748.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/748.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/749.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/749.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/750.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/750.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/751.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/751.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/751.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/752.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/752.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/753.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/753.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/754.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/754.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/755.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/755.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/756.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/756.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/757.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/757.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/758.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/758.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/759.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/759.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/759.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/760.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/760.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/761.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/761.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/762.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/762.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/763.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/763.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/764.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/764.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/764.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/765.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/765.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/766.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/766.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/767.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/767.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/768.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/768.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/769.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/769.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/770.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/770.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/771.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/771.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/771.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/772.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/772.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/773.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/773.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/774.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/774.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/775.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/775.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/776.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/776.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/777.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/777.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/778.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/778.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/779.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/779.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/779.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/780.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/780.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/781.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/781.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/782.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/782.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/782.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/783.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/783.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/784.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/784.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/785.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/785.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/786.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/786.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/787.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/787.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/788.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/788.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/789.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/789.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/790.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/790.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/791.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/791.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/792.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/792.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/793.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/793.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/794.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/794.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/795.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/795.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/795.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/795.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/796.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/796.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/796.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/797.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/797.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/797.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/798.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/798.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/798.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/799.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/799.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/799.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/800.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/800.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/800.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/801.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/801.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/801.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/802.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/802.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/802.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/803.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/803.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/803.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/804.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/804.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/804.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/805.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/805.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/805.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/805.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/806.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/806.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/806.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/806.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/807.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/807.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/807.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/808.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/808.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/808.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/809.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/809.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/809.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/810.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/810.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/810.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/811.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/811.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/811.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/812.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/812.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/812.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/812.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/813.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/813.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/813.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/814.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/814.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/814.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/815.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/815.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/815.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/816.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/816.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/816.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/817.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/817.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/817.png\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|   | 44134/62614 [5:14:36<1:27:55,  3.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18790.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18790.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18791.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18791.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18792.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18792.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18792.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18793.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18793.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18794.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18794.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18795.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18795.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18796.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18796.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18797.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18797.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18798.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18798.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18799.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18799.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18800.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18800.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18801.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18801.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18801.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18802.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18802.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18803.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18803.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18804.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18804.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18804.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18805.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18805.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18805.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18805.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18806.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18806.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18806.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18807.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18807.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18807.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18808.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18808.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18808.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18809.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18809.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18809.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18810.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18810.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18810.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18811.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18811.png\n",
            "Failed to read: /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/18811.png\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 62614/62614 [7:24:37<00:00,  2.35it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for idx, row in tqdm(df_clean.iterrows(), total=len(df_clean)):\n",
        "    crop_path = row[\"crop_path\"]\n",
        "    ann = int(row[\"annotationID\"])\n",
        "\n",
        "    crop = cv2.imread(crop_path)\n",
        "    if crop is None:\n",
        "        print(\"Failed to read:\", crop_path)\n",
        "        continue\n",
        "\n",
        "    mask = get_sam_mask(crop)\n",
        "    cv2.imwrite(f\"{masks_dir}/{ann}.png\", mask)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images_dir = \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/images\"\n",
        "crops_dir  = \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops\"\n",
        "masks_dir = \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks\""
      ],
      "metadata": {
        "id": "AEK92u2W3irq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "images_dir = \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/images\"\n",
        "crops_dir  = \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops\"\n",
        "masks_dir  = \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks\"\n",
        "\n",
        "def list_files_with_exts(path, exts=(\".png\", \".jpg\", \".jpeg\", \".tif\", \".tiff\")):\n",
        "    return sorted([\n",
        "        f for f in os.listdir(path)\n",
        "        if f.lower().endswith(exts)\n",
        "    ])\n",
        "\n",
        "image_files = list_files_with_exts(images_dir)\n",
        "crop_files  = list_files_with_exts(crops_dir)\n",
        "mask_files  = list_files_with_exts(masks_dir)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"annotation_id\": [os.path.splitext(f)[0] for f in image_files],\n",
        "    \"image_path\": [os.path.join(images_dir, f) for f in image_files]\n",
        "})\n",
        "\n",
        "# Add crop path only if exists\n",
        "df[\"crop_path\"] = df[\"annotation_id\"].apply(\n",
        "    lambda x: os.path.join(crops_dir, x + \".png\") if (x + \".png\") in crop_files\n",
        "              else os.path.join(crops_dir, x + \".jpg\") if (x + \".jpg\") in crop_files\n",
        "              else None\n",
        ")\n",
        "\n",
        "# Add mask path only if exists\n",
        "df[\"mask_path\"] = df[\"annotation_id\"].apply(\n",
        "    lambda x: os.path.join(masks_dir, x + \".png\") if (x + \".png\") in mask_files\n",
        "              else os.path.join(masks_dir, x + \".jpg\") if (x + \".jpg\") in mask_files\n",
        "              else None\n",
        ")\n",
        "\n",
        "# Drop rows missing ANY required component\n",
        "df_clean = df.dropna(subset=[\"crop_path\", \"mask_path\"]).reset_index(drop=True)\n",
        "\n",
        "print(\"Total images:\", len(image_files))\n",
        "print(\"Usable complete samples:\", len(df_clean))\n",
        "\n",
        "df_clean.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "JxgKPdjgZYzM",
        "outputId": "03b8cfef-3ea6-4230-c91a-9c877222d1a9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images: 500\n",
            "Usable complete samples: 403\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  annotation_id                                         image_path  \\\n",
              "0           100  /content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...   \n",
              "1           101  /content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...   \n",
              "2           102  /content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...   \n",
              "3           103  /content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...   \n",
              "4           104  /content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...   \n",
              "\n",
              "                                           crop_path  \\\n",
              "0  /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/1...   \n",
              "1  /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/1...   \n",
              "2  /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/1...   \n",
              "3  /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/1...   \n",
              "4  /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/1...   \n",
              "\n",
              "                                           mask_path  \n",
              "0  /content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/1...  \n",
              "1  /content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/1...  \n",
              "2  /content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/1...  \n",
              "3  /content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/1...  \n",
              "4  /content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/1...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5815b606-7857-40f1-92f5-b6917e5b88cc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>annotation_id</th>\n",
              "      <th>image_path</th>\n",
              "      <th>crop_path</th>\n",
              "      <th>mask_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/1...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>101</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/1...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>102</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/1...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>103</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/1...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>104</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/1...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5815b606-7857-40f1-92f5-b6917e5b88cc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5815b606-7857-40f1-92f5-b6917e5b88cc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5815b606-7857-40f1-92f5-b6917e5b88cc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-24965852-77ef-4858-8807-28ffc7b916db\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-24965852-77ef-4858-8807-28ffc7b916db')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-24965852-77ef-4858-8807-28ffc7b916db button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_clean",
              "summary": "{\n  \"name\": \"df_clean\",\n  \"rows\": 403,\n  \"fields\": [\n    {\n      \"column\": \"annotation_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 403,\n        \"samples\": [\n          \"220\",\n          \"432\",\n          \"434\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 403,\n        \"samples\": [\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/220.tiff\",\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/432.tiff\",\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/434.tiff\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"crop_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 403,\n        \"samples\": [\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/220.png\",\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/432.png\",\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/434.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mask_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 403,\n        \"samples\": [\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/220.png\",\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/432.png\",\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/434.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "IMG_SIZE = (256, 256)\n",
        "BATCH_SIZE = 8\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "def load_and_resize(path, channels):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_image(img, channels=channels, expand_animations=False)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    img = tf.image.resize(img, IMG_SIZE)\n",
        "    return img\n",
        "\n",
        "def load_fusion(image_path, crop_path, mask_path):\n",
        "    image = load_and_resize(image_path, 3)\n",
        "    crop  = load_and_resize(crop_path, 3)\n",
        "    mask  = load_and_resize(mask_path, 1)\n",
        "    mask  = tf.where(mask > 0.5, 1.0, 0.0)\n",
        "\n",
        "    fused = tf.concat([image, crop, mask], axis=-1)    # (H, W, 7)\n",
        "    return fused, mask\n",
        "\n",
        "def build_dataset(df, batch_size=BATCH_SIZE, shuffle=False):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(\n",
        "        (df[\"image_path\"], df[\"crop_path\"], df[\"mask_path\"])\n",
        "    )\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size=len(df))\n",
        "\n",
        "    ds = ds.map(lambda a,b,c: load_fusion(a,b,c),\n",
        "                num_parallel_calls=AUTOTUNE)\n",
        "    ds = ds.batch(batch_size).prefetch(AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "# Create splits\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(df_clean, test_size=0.15, random_state=42)\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42)\n",
        "\n",
        "train_ds = build_dataset(train_df, shuffle=True)\n",
        "val_ds   = build_dataset(val_df)\n",
        "test_ds  = build_dataset(test_df)\n",
        "\n",
        "len(train_df), len(val_df), len(test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KY0KqQCzZdGa",
        "outputId": "20c6f604-2291-429f-b4d4-48419a61182b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(307, 35, 61)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "images_dir = \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/images\"\n",
        "crops_dir  = \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops\"\n",
        "masks_dir  = \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks\"\n",
        "\n",
        "def list_files(path):\n",
        "    return sorted([f for f in os.listdir(path) if not f.startswith(\".\")])\n",
        "\n",
        "crop_files = list_files(crops_dir)\n",
        "mask_files = list_files(masks_dir)\n",
        "image_files = list_files(images_dir)\n",
        "\n",
        "# Extract annotation_id from crop files (remove extension)\n",
        "anno_ids = [os.path.splitext(f)[0] for f in crop_files]\n",
        "\n",
        "rows = []\n",
        "\n",
        "for anno in anno_ids:\n",
        "    crop_path = os.path.join(crops_dir, anno + \".png\")\n",
        "    if not os.path.exists(crop_path):\n",
        "        crop_path = os.path.join(crops_dir, anno + \".jpg\")\n",
        "        if not os.path.exists(crop_path):\n",
        "            continue\n",
        "\n",
        "    mask_path = os.path.join(masks_dir, anno + \".png\")\n",
        "    if not os.path.exists(mask_path):\n",
        "        mask_path = os.path.join(masks_dir, anno + \".jpg\")\n",
        "        if not os.path.exists(mask_path):\n",
        "            continue\n",
        "\n",
        "    # determine parent image\n",
        "    # Usually annotation filename contains original patch/image ID\n",
        "    image_id = anno.split(\"_\")[0]   # IMPORTANT: adjust if needed\n",
        "\n",
        "    # find matching image file\n",
        "    possible_imgs = [\n",
        "        os.path.join(images_dir, image_id + ext)\n",
        "        for ext in [\".png\", \".jpg\", \".jpeg\", \".tif\", \".tiff\"]\n",
        "    ]\n",
        "\n",
        "    image_path = None\n",
        "    for p in possible_imgs:\n",
        "        if os.path.exists(p):\n",
        "            image_path = p\n",
        "            break\n",
        "\n",
        "    if image_path is None:\n",
        "        continue\n",
        "\n",
        "    rows.append([anno, image_path, crop_path, mask_path])\n",
        "\n",
        "df = pd.DataFrame(rows, columns=[\"annotation_id\", \"image_path\", \"crop_path\", \"mask_path\"])\n",
        "\n",
        "print(\"Total annotations:\", len(anno_ids))\n",
        "print(\"Usable complete samples:\", len(df))\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "WzdtlxG4Znta",
        "outputId": "4b94568c-a5e2-4624-8719-573ea7222164"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total annotations: 26129\n",
            "Usable complete samples: 403\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  annotation_id                                         image_path  \\\n",
              "0           100  /content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...   \n",
              "1           101  /content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...   \n",
              "2           102  /content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...   \n",
              "3           103  /content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...   \n",
              "4           104  /content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...   \n",
              "\n",
              "                                           crop_path  \\\n",
              "0  /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/1...   \n",
              "1  /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/1...   \n",
              "2  /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/1...   \n",
              "3  /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/1...   \n",
              "4  /content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/1...   \n",
              "\n",
              "                                           mask_path  \n",
              "0  /content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/1...  \n",
              "1  /content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/1...  \n",
              "2  /content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/1...  \n",
              "3  /content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/1...  \n",
              "4  /content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/1...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c45c694-c82a-4232-93f3-9367f10ec408\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>annotation_id</th>\n",
              "      <th>image_path</th>\n",
              "      <th>crop_path</th>\n",
              "      <th>mask_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/1...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>101</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/1...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>102</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/1...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>103</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/1...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>104</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/1...</td>\n",
              "      <td>/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c45c694-c82a-4232-93f3-9367f10ec408')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3c45c694-c82a-4232-93f3-9367f10ec408 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3c45c694-c82a-4232-93f3-9367f10ec408');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c6a1f0a4-04e2-4865-92ef-ddd942ea7fbe\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c6a1f0a4-04e2-4865-92ef-ddd942ea7fbe')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c6a1f0a4-04e2-4865-92ef-ddd942ea7fbe button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 403,\n  \"fields\": [\n    {\n      \"column\": \"annotation_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 403,\n        \"samples\": [\n          \"220\",\n          \"432\",\n          \"434\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 403,\n        \"samples\": [\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/220.tiff\",\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/432.tiff\",\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/images/434.tiff\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"crop_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 403,\n        \"samples\": [\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/220.png\",\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/432.png\",\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/crops/434.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mask_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 403,\n        \"samples\": [\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/220.png\",\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/432.png\",\n          \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/masks/434.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 128   # A100 can handle this easily"
      ],
      "metadata": {
        "id": "Fn-BzG0Cy3PB"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def load_fused(crop_path, mask_path, label):\n",
        "    crop = tf.io.read_file(crop_path)\n",
        "    crop = tf.image.decode_png(crop, channels=3)\n",
        "    crop = tf.image.resize(crop, IMG_SIZE)\n",
        "    crop = tf.image.convert_image_dtype(crop, tf.float32)\n",
        "\n",
        "    mask = tf.io.read_file(mask_path)\n",
        "    mask = tf.image.decode_png(mask, channels=1)\n",
        "    mask = tf.image.resize(mask, IMG_SIZE)\n",
        "    mask = tf.image.convert_image_dtype(mask, tf.float32)\n",
        "\n",
        "    fused = tf.concat([crop, mask], axis=-1)\n",
        "    return fused, tf.cast(label, tf.float32)"
      ],
      "metadata": {
        "id": "Id95RW9Jy43s"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_fast_dataset(df, shuffle=False, augment=False):\n",
        "    crops  = tf.constant(df[\"crop_path\"].tolist())\n",
        "    masks  = tf.constant(df[\"mask_path\"].tolist())\n",
        "    labels = tf.constant(df[\"class\"].astype(\"float32\").tolist())\n",
        "\n",
        "    ds = tf.data.Dataset.from_tensor_slices((crops, masks, labels))\n",
        "\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(len(df), seed=42)\n",
        "\n",
        "    ds = ds.map(load_fused, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    if augment:\n",
        "        ds = ds.map(augment_fast, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    ds = ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "    return ds"
      ],
      "metadata": {
        "id": "dT1xRPFoy6T0"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for X, y in train_ds.take(1):\n",
        "    print(X.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7kfTZ--y7zb",
        "outputId": "39faf11e-8bfa-4f49-fc73-60dc84d8f082"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 224, 224, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy('mixed_float16')"
      ],
      "metadata": {
        "id": "brgQygaFy_LE"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!watch -n 2 nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41dsdwJB3JbN",
        "outputId": "6b433782-b4c8-4dfb-cc03-f704162f4c0d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?1l\u001b>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -f /content/cache_mitotic.tfcache*"
      ],
      "metadata": {
        "id": "aPBdMNB00agO"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = make_dataset_from_crops(train_crops_tf, train_labels_tf, shuffle=True, augment=True)\n",
        "val_ds   = make_dataset_from_crops(val_crops_tf, val_labels_tf)\n",
        "test_ds  = make_dataset_from_crops(test_crops_tf, test_labels_tf)"
      ],
      "metadata": {
        "id": "wMbPEr4S3s7C"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=50,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMTQuXb33-O1",
        "outputId": "1dc9aca3-f363-4c2c-cf53-efdcc73e4b6b"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12s/step - accuracy: 0.4285 - loss: -43.9185 \n",
            "Epoch 1: val_accuracy improved from -inf to 0.44243, saving model to /content/drive/MyDrive/MIDOGPP/MIDOGpp/models/mobilenet_a100_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1952s\u001b[0m 12s/step - accuracy: 0.4285 - loss: -44.2192 - val_accuracy: 0.4424 - val_loss: -509.3212 - learning_rate: 1.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.4286 - loss: -319.3235\n",
            "Epoch 2: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 78ms/step - accuracy: 0.4285 - loss: -320.5086 - val_accuracy: 0.4424 - val_loss: -919.9971 - learning_rate: 1.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.4286 - loss: -737.7177\n",
            "Epoch 3: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 80ms/step - accuracy: 0.4285 - loss: -739.2674 - val_accuracy: 0.4424 - val_loss: -1298.5485 - learning_rate: 1.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.4286 - loss: -1264.2596\n",
            "Epoch 4: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 77ms/step - accuracy: 0.4285 - loss: -1266.2213 - val_accuracy: 0.4424 - val_loss: -3168.6619 - learning_rate: 1.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.4286 - loss: -1924.4923\n",
            "Epoch 5: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 75ms/step - accuracy: 0.4285 - loss: -1926.7335 - val_accuracy: 0.4424 - val_loss: -4809.2778 - learning_rate: 1.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4286 - loss: -2688.9399\n",
            "Epoch 6: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.4285 - loss: -2691.7617 - val_accuracy: 0.4424 - val_loss: -7826.7280 - learning_rate: 1.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.4286 - loss: -3577.1860\n",
            "Epoch 7: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 75ms/step - accuracy: 0.4285 - loss: -3580.4854 - val_accuracy: 0.4424 - val_loss: -8291.8994 - learning_rate: 1.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4286 - loss: -4610.0269\n",
            "Epoch 8: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 75ms/step - accuracy: 0.4285 - loss: -4613.4448 - val_accuracy: 0.4424 - val_loss: -10182.6328 - learning_rate: 1.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4286 - loss: -5778.7075\n",
            "Epoch 9: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.4285 - loss: -5782.4072 - val_accuracy: 0.4424 - val_loss: -12376.3076 - learning_rate: 1.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4286 - loss: -7039.0986\n",
            "Epoch 10: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 75ms/step - accuracy: 0.4285 - loss: -7043.2583 - val_accuracy: 0.4424 - val_loss: -14979.9033 - learning_rate: 1.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4286 - loss: -8280.8154\n",
            "Epoch 11: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.4285 - loss: -8286.0400 - val_accuracy: 0.4424 - val_loss: -16038.9160 - learning_rate: 1.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4286 - loss: -9865.6982\n",
            "Epoch 12: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 75ms/step - accuracy: 0.4285 - loss: -9871.0352 - val_accuracy: 0.4424 - val_loss: -16653.7910 - learning_rate: 1.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.4286 - loss: -11468.1973\n",
            "Epoch 13: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 75ms/step - accuracy: 0.4285 - loss: -11473.8252 - val_accuracy: 0.4424 - val_loss: -17829.4590 - learning_rate: 1.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4286 - loss: -13232.5996\n",
            "Epoch 14: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.4285 - loss: -13239.0986 - val_accuracy: 0.4424 - val_loss: -22433.8223 - learning_rate: 1.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4286 - loss: -15110.3486\n",
            "Epoch 15: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.4285 - loss: -15117.0498 - val_accuracy: 0.4424 - val_loss: -25391.4746 - learning_rate: 1.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4286 - loss: -17138.0410\n",
            "Epoch 16: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 75ms/step - accuracy: 0.4285 - loss: -17144.5137 - val_accuracy: 0.4424 - val_loss: -28127.5234 - learning_rate: 1.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4286 - loss: -19265.1270\n",
            "Epoch 17: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 77ms/step - accuracy: 0.4285 - loss: -19271.8711 - val_accuracy: 0.4424 - val_loss: -33093.8633 - learning_rate: 1.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4286 - loss: -21567.3633\n",
            "Epoch 18: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.4285 - loss: -21573.5586 - val_accuracy: 0.4424 - val_loss: -34102.7109 - learning_rate: 1.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4286 - loss: -23875.6250\n",
            "Epoch 19: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.4285 - loss: -23883.4238 - val_accuracy: 0.4424 - val_loss: -39631.7344 - learning_rate: 1.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.4286 - loss: -26312.6250\n",
            "Epoch 20: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 75ms/step - accuracy: 0.4285 - loss: -26321.0391 - val_accuracy: 0.4424 - val_loss: -39736.6836 - learning_rate: 1.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4286 - loss: -28987.9238\n",
            "Epoch 21: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.4285 - loss: -28996.3945 - val_accuracy: 0.4424 - val_loss: -40930.4453 - learning_rate: 1.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4286 - loss: -31729.8574\n",
            "Epoch 22: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.4285 - loss: -31738.3242 - val_accuracy: 0.4424 - val_loss: -43226.8945 - learning_rate: 1.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.4286 - loss: -34701.8750\n",
            "Epoch 23: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 74ms/step - accuracy: 0.4285 - loss: -34710.1719 - val_accuracy: 0.4424 - val_loss: -43805.9883 - learning_rate: 1.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.4286 - loss: -37461.2305\n",
            "Epoch 24: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 75ms/step - accuracy: 0.4285 - loss: -37470.1406 - val_accuracy: 0.4424 - val_loss: -43893.7812 - learning_rate: 1.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4286 - loss: -40398.8125\n",
            "Epoch 25: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.4285 - loss: -40408.6680 - val_accuracy: 0.4424 - val_loss: -49844.4219 - learning_rate: 1.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4286 - loss: -43522.1602\n",
            "Epoch 26: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.4285 - loss: -43532.3594 - val_accuracy: 0.4424 - val_loss: -50797.1367 - learning_rate: 1.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4286 - loss: -46736.3203\n",
            "Epoch 27: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.4285 - loss: -46748.7383 - val_accuracy: 0.4424 - val_loss: -52558.9180 - learning_rate: 1.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4286 - loss: -50393.0000\n",
            "Epoch 28: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.4285 - loss: -50402.6016 - val_accuracy: 0.4424 - val_loss: -55845.6992 - learning_rate: 1.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4286 - loss: -53468.0156\n",
            "Epoch 29: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.4285 - loss: -53480.6875 - val_accuracy: 0.4424 - val_loss: -57228.4023 - learning_rate: 1.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4286 - loss: -57237.3086\n",
            "Epoch 30: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.4285 - loss: -57248.7461 - val_accuracy: 0.4424 - val_loss: -59658.7305 - learning_rate: 1.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4286 - loss: -61309.2539\n",
            "Epoch 31: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.4285 - loss: -61320.0820 - val_accuracy: 0.4424 - val_loss: -57677.1445 - learning_rate: 1.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4286 - loss: -65145.2461\n",
            "Epoch 32: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.4285 - loss: -65156.6094 - val_accuracy: 0.4424 - val_loss: -62727.0586 - learning_rate: 1.0000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4286 - loss: -69189.4844\n",
            "Epoch 33: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.4285 - loss: -69201.4531 - val_accuracy: 0.4424 - val_loss: -63189.9883 - learning_rate: 1.0000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4286 - loss: -73480.7109\n",
            "Epoch 34: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.4285 - loss: -73494.3359 - val_accuracy: 0.4424 - val_loss: -72382.8125 - learning_rate: 1.0000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4286 - loss: -77595.6328\n",
            "Epoch 35: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.4285 - loss: -77609.6953 - val_accuracy: 0.4424 - val_loss: -80353.3203 - learning_rate: 1.0000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4286 - loss: -82083.8828\n",
            "Epoch 36: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.4285 - loss: -82097.3594 - val_accuracy: 0.4424 - val_loss: -83671.5938 - learning_rate: 1.0000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4286 - loss: -86592.3281\n",
            "Epoch 37: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.4285 - loss: -86604.3203 - val_accuracy: 0.4424 - val_loss: -90269.7031 - learning_rate: 1.0000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4286 - loss: -90939.1562\n",
            "Epoch 38: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.4285 - loss: -90955.6328 - val_accuracy: 0.4424 - val_loss: -100301.6172 - learning_rate: 1.0000e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4286 - loss: -95965.1641\n",
            "Epoch 39: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.4285 - loss: -95978.2812 - val_accuracy: 0.4424 - val_loss: -93995.0703 - learning_rate: 1.0000e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.4286 - loss: -99972.7031\n",
            "Epoch 40: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 74ms/step - accuracy: 0.4285 - loss: -99992.8906 - val_accuracy: 0.4424 - val_loss: -96459.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4286 - loss: -105534.1641\n",
            "Epoch 41: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.4285 - loss: -105548.0469 - val_accuracy: 0.4424 - val_loss: -106413.7734 - learning_rate: 1.0000e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4286 - loss: -110802.5234\n",
            "Epoch 42: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.4285 - loss: -110818.9688 - val_accuracy: 0.4424 - val_loss: -93074.7344 - learning_rate: 1.0000e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4286 - loss: -116473.5078\n",
            "Epoch 43: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.4285 - loss: -116487.9062 - val_accuracy: 0.4424 - val_loss: -101376.6406 - learning_rate: 1.0000e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4286 - loss: -122035.3281\n",
            "Epoch 44: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.4285 - loss: -122047.8438 - val_accuracy: 0.4424 - val_loss: -117324.2656 - learning_rate: 1.0000e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4286 - loss: -127083.2344\n",
            "Epoch 45: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.4285 - loss: -127099.8516 - val_accuracy: 0.4424 - val_loss: -110211.1172 - learning_rate: 1.0000e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4286 - loss: -133011.4375\n",
            "Epoch 46: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 75ms/step - accuracy: 0.4285 - loss: -133031.8594 - val_accuracy: 0.4424 - val_loss: -124640.9766 - learning_rate: 1.0000e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4286 - loss: -139298.5625\n",
            "Epoch 47: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 75ms/step - accuracy: 0.4285 - loss: -139316.8438 - val_accuracy: 0.4424 - val_loss: -121277.3438 - learning_rate: 1.0000e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4286 - loss: -144900.4531\n",
            "Epoch 48: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 77ms/step - accuracy: 0.4285 - loss: -144918.0938 - val_accuracy: 0.4424 - val_loss: -144710.2500 - learning_rate: 1.0000e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4286 - loss: -150862.5000\n",
            "Epoch 49: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 75ms/step - accuracy: 0.4285 - loss: -150880.5000 - val_accuracy: 0.4424 - val_loss: -120439.0938 - learning_rate: 1.0000e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m165/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4286 - loss: -156893.1406\n",
            "Epoch 50: val_accuracy did not improve from 0.44243\n",
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.4285 - loss: -156908.0312 - val_accuracy: 0.4424 - val_loss: -160035.8750 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 50.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 128\n",
        "AUTO = tf.data.AUTOTUNE\n",
        "\n",
        "def mask_from_crop(crop_path):\n",
        "    return tf.strings.regex_replace(crop_path, \"/crops/\", \"/masks/\")\n",
        "\n",
        "@tf.function\n",
        "def load_fused(crop_path, label):\n",
        "    mask_path = mask_from_crop(crop_path)\n",
        "\n",
        "    crop = tf.io.read_file(crop_path)\n",
        "    crop = tf.image.decode_png(crop, channels=3)\n",
        "    crop = tf.image.convert_image_dtype(crop, tf.float32)\n",
        "    crop = tf.image.resize(crop, IMG_SIZE)\n",
        "\n",
        "    mask = tf.io.read_file(mask_path)\n",
        "    mask = tf.image.decode_png(mask, channels=1)\n",
        "    mask = tf.image.convert_image_dtype(mask, tf.float32)\n",
        "    mask = tf.image.resize(mask, IMG_SIZE)\n",
        "\n",
        "    fused = tf.concat([crop, mask], axis=-1)\n",
        "    return fused, label\n",
        "\n",
        "def make_dataset(paths, labels):\n",
        "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
        "    ds = ds.map(load_fused, num_parallel_calls=AUTO)\n",
        "    ds = ds.batch(BATCH_SIZE).prefetch(AUTO)\n",
        "    return ds\n",
        "\n",
        "test_ds = make_dataset(test_paths, test_labels)"
      ],
      "metadata": {
        "id": "_bJYHCg1GUjd"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def build_mobilenet():\n",
        "    inp = layers.Input(shape=(224,224,4))\n",
        "\n",
        "    # Split channels: RGB (3) + mask (1)\n",
        "    rgb = inp[..., :3]\n",
        "    mask = inp[..., 3:]\n",
        "\n",
        "    # MobileNetV2 backbone\n",
        "    base = tf.keras.applications.MobileNetV2(\n",
        "        input_shape=(224,224,3),\n",
        "        include_top=False,\n",
        "        weights=\"imagenet\"\n",
        "    )\n",
        "    x = base(rgb)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Mask branch (simple CNN)\n",
        "    m = layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\")(mask)\n",
        "    m = layers.GlobalAveragePooling2D()(m)\n",
        "\n",
        "    # Fusion\n",
        "    z = layers.Concatenate()([x, m])\n",
        "    z = layers.Dense(128, activation=\"relu\")(z)\n",
        "    z = layers.Dropout(0.3)(z)\n",
        "    out = layers.Dense(1, activation=\"sigmoid\")(z)\n",
        "\n",
        "    return models.Model(inp, out)\n"
      ],
      "metadata": {
        "id": "_c7BljTsGjei"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_mobilenet()\n",
        "# OR build_efficientnet()\n",
        "# OR build_resnet()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZB40EOn4GHMO",
        "outputId": "2d24171c-a426-40c7-f959-0bd3a23ee886"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt_path = \"/content/drive/MyDrive/MIDOGPP/MIDOGpp/models/mobilenet_best.h5\"\n",
        "model.load_weights(ckpt_path)\n",
        "print(\"Loaded best model weights!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLymOiANGFN9",
        "outputId": "4973dd74-01d0-4fb7-9adf-eef2cd99806a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded best model weights!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "IYhLTepwG9iI"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(test_ds)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nmas2UmGxz1",
        "outputId": "87ee2b46-79a8-4338-8668-effac5c8d0f9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 4s/step - accuracy: 0.7941 - loss: 1.5249\n",
            "Test Loss: 1.563114881515503\n",
            "Test Accuracy: 0.7872177362442017\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "authorship_tag": "ABX9TyPQV6kgef1xisXd5u4u8xX+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}