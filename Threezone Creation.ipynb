{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZZdZEO3QaOOl32TesjUZL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a2m-dotcom/DLBCL_Pub/blob/main/Threezone%20Creation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reprocess_missing_wsis.py\n",
        "# Usage: run in same env where your previous pipeline ran (so dependencies exist).\n",
        "# Adjust ROOT and out_dir paths below if required.\n",
        "\n",
        "import json, math, traceback\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "from scipy.ndimage import gaussian_filter, binary_dilation, label, generate_binary_structure\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# ---------------- CONFIG - adjust if needed ----------------\n",
        "ROOT = Path(\"/content/drivee/MyDrive/DLBCLMORPH/Results\")   # top-level WSI folder\n",
        "out_dir = ROOT / \"zone_counts_batch_outputs\"         # same run folder used earlier\n",
        "per_wsi_csv_folder = out_dir / \"per_wsi_csvs\"\n",
        "per_wsi_csv_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# processing params (match what you used)\n",
        "downscale = 100\n",
        "gaussian_sigma = 1.0\n",
        "dilation_iters = 10\n",
        "min_component_size = 100\n",
        "zone2_dilation_size = 50\n",
        "restrict_zone3_to_tissue = False\n",
        "save_qc_images = True\n",
        "\n",
        "# helper: robustly find geojson/json file for a wsi (nested or flat or \"Copy of\")\n",
        "def find_geojson_for_wsi(wsi_folder: Path):\n",
        "    # prefer nested: wsi/wsi/cells.geojson\n",
        "    nested = wsi_folder / wsi_folder.name / \"cells.geojson\"\n",
        "    if nested.exists(): return nested\n",
        "    # try nested with other names\n",
        "    nested_other = list((wsi_folder / wsi_folder.name).glob(\"*.geojson\")) + list((wsi_folder / wsi_folder.name).glob(\"*.json\"))\n",
        "    if nested_other:\n",
        "        return nested_other[0]\n",
        "    # flat path\n",
        "    flat = wsi_folder / \"cells.geojson\"\n",
        "    if flat.exists(): return flat\n",
        "    # fallback patterns: any file containing wsi id or \"cells\" in filename\n",
        "    for p in sorted(wsi_folder.glob(\"*cells*.geojson\")):\n",
        "        return p\n",
        "    for p in sorted(wsi_folder.glob(f\"*{wsi_folder.name}*.geojson\")):\n",
        "        return p\n",
        "    for p in sorted(wsi_folder.glob(\"*.geojson\")):\n",
        "        return p\n",
        "    for p in sorted(wsi_folder.glob(\"*.json\")):\n",
        "        return p\n",
        "    # also try files whose names start with \"Copy of {wsi}\"\n",
        "    for p in sorted(wsi_folder.glob(\"Copy*\")):\n",
        "        if p.suffix.lower() in (\".geojson\", \".json\"):\n",
        "            return p\n",
        "    return None\n",
        "\n",
        "# small utility functions copied/adapted from your pipeline\n",
        "def to_mask_coord_floor(x_full, y_full, downscale):\n",
        "    return int(math.floor(float(x_full) / downscale)), int(math.floor(float(y_full) / downscale))\n",
        "\n",
        "def centroid_of_ring(ring):\n",
        "    xs = [p[0] for p in ring if p is not None]\n",
        "    ys = [p[1] for p in ring if p is not None]\n",
        "    if len(xs) == 0:\n",
        "        return None, None\n",
        "    return sum(xs)/len(xs), sum(ys)/len(ys)\n",
        "\n",
        "def rasterize_polygons_to_canvas(polygons_by_class, canvas_w, canvas_h, downscale):\n",
        "    canvas = Image.new(\"RGB\", (canvas_w, canvas_h), (0,0,0))\n",
        "    draw = ImageDraw.Draw(canvas)\n",
        "    tissue_mask = np.zeros((canvas_h, canvas_w), dtype=np.uint8)\n",
        "    for cls, polylist in polygons_by_class.items():\n",
        "        color = (200,200,200)\n",
        "        for poly in polylist:\n",
        "            if not poly: continue\n",
        "            outer = poly[0] if isinstance(poly, list) and len(poly)>0 else poly\n",
        "            pts = [ to_mask_coord_floor(x,y, downscale) for x,y in outer ]\n",
        "            pts_clamped = [ (max(0,min(canvas_w-1,xx)), max(0,min(canvas_h-1,yy))) for xx,yy in pts ]\n",
        "            if len(pts_clamped) >= 3:\n",
        "                try:\n",
        "                    draw.polygon(pts_clamped, fill=color)\n",
        "                    mask_temp = Image.new(\"L\", (canvas_w, canvas_h), 0)\n",
        "                    ImageDraw.Draw(mask_temp).polygon(pts_clamped, outline=1, fill=1)\n",
        "                    tissue_mask = np.maximum(tissue_mask, np.array(mask_temp, dtype=np.uint8))\n",
        "                except Exception:\n",
        "                    continue\n",
        "    return canvas, tissue_mask\n",
        "\n",
        "def make_downscaled_tumor_mask(tumor_polygons, downscale, canvas_w, canvas_h):\n",
        "    mask_img = Image.new(\"L\", (canvas_w, canvas_h), 0)\n",
        "    draw = ImageDraw.Draw(mask_img)\n",
        "    for poly in tumor_polygons:\n",
        "        if not poly: continue\n",
        "        outer = poly[0] if isinstance(poly, list) and len(poly)>0 else poly\n",
        "        pts = [ to_mask_coord_floor(x,y, downscale) for x,y in outer ]\n",
        "        pts_clamped = [ (max(0,min(canvas_w-1,xx)), max(0,min(canvas_h-1,yy))) for xx,yy in pts ]\n",
        "        if len(pts_clamped) >= 3:\n",
        "            try:\n",
        "                draw.polygon(pts_clamped, outline=1, fill=1)\n",
        "            except Exception:\n",
        "                continue\n",
        "    return np.array(mask_img, dtype=np.uint8)\n",
        "\n",
        "def postprocess_mask(binary_mask, gaussian_sigma=1.0, dilation_iters=5, min_component_size=100):\n",
        "    smooth = gaussian_filter(binary_mask.astype(float), sigma=gaussian_sigma)\n",
        "    smooth = (smooth > 0.5).astype(np.uint8)\n",
        "    struct = generate_binary_structure(2, 2)\n",
        "    dil = binary_dilation(smooth, structure=struct, iterations=dilation_iters).astype(np.uint8)\n",
        "    inv = binary_dilation((dil==0).astype(np.uint8), structure=struct, iterations=dilation_iters).astype(np.uint8)\n",
        "    smooth = (1 - inv).astype(np.uint8)\n",
        "    labeled_array, num_features = label(smooth, structure=struct)\n",
        "    if num_features > 0:\n",
        "        for lab in range(1, num_features+1):\n",
        "            if np.sum(labeled_array == lab) < min_component_size:\n",
        "                smooth[labeled_array == lab] = 0\n",
        "        labeled_array, _ = label(smooth, structure=struct)\n",
        "    else:\n",
        "        labeled_array = np.zeros_like(smooth)\n",
        "    return smooth, labeled_array\n",
        "\n",
        "def get_zone_two(arr, dilation_size=50):\n",
        "    structuring_element = np.ones((dilation_size, dilation_size), dtype=bool)\n",
        "    dilated_array = binary_dilation(arr.astype(bool), structure=structuring_element).astype(arr.dtype)\n",
        "    zone_two = dilated_array - arr\n",
        "    return (zone_two > 0).astype(np.uint8)\n",
        "\n",
        "# ---------- helper: safe WSI list discovery ----------\n",
        "def list_input_wsis(root: Path):\n",
        "    # consider directories whose names look like \"<digits>_<digit>\" but be permissive\n",
        "    return sorted([p.name for p in root.iterdir() if p.is_dir()])\n",
        "\n",
        "def list_output_wsis(out_folder: Path):\n",
        "    if not out_folder.exists(): return []\n",
        "    return sorted([p.name for p in out_folder.iterdir() if p.is_dir()])\n",
        "\n",
        "# --------- single-WSI small runner (a trimmed version of your main loop) ----------\n",
        "def run_one_wsi_by_id(wsi_id: str):\n",
        "    wsi_folder = ROOT / wsi_id\n",
        "    geojson_path = find_geojson_for_wsi(wsi_folder)\n",
        "    if geojson_path is None:\n",
        "        return dict(status=\"missing_geojson\", msg=f\"no geojson found in {wsi_folder}\")\n",
        "\n",
        "    try:\n",
        "        with open(geojson_path, \"r\") as f:\n",
        "            gj = json.load(f)\n",
        "    except Exception as e:\n",
        "        return dict(status=\"read_error\", msg=str(e))\n",
        "\n",
        "    features = gj if isinstance(gj, list) else gj.get(\"features\", [])\n",
        "    if not features:\n",
        "        return dict(status=\"no_features\", msg=\"no features in file\")\n",
        "\n",
        "    classes = defaultdict(list)\n",
        "    global_max_x = 0.0\n",
        "    global_max_y = 0.0\n",
        "\n",
        "    for feat in features:\n",
        "        if not isinstance(feat, dict): continue\n",
        "        props = feat.get(\"properties\", {}) or {}\n",
        "        cls_field = props.get(\"classification\", props.get(\"class\"))\n",
        "        if isinstance(cls_field, dict):\n",
        "            cls_name = cls_field.get(\"name\", \"Unknown\")\n",
        "        else:\n",
        "            cls_name = str(cls_field) if cls_field is not None else \"Unknown\"\n",
        "        geom = feat.get(\"geometry\", {}) or {}\n",
        "        gtype = geom.get(\"type\")\n",
        "        coords = geom.get(\"coordinates\") or []\n",
        "        if gtype == \"Polygon\":\n",
        "            polys = [coords]\n",
        "        elif gtype == \"MultiPolygon\":\n",
        "            polys = coords\n",
        "        else:\n",
        "            polys = []\n",
        "        classes[cls_name].extend(polys)\n",
        "        for poly in polys:\n",
        "            for ring in poly:\n",
        "                for x,y in ring:\n",
        "                    if x is None or y is None: continue\n",
        "                    global_max_x = max(global_max_x, float(x))\n",
        "                    global_max_y = max(global_max_y, float(y))\n",
        "\n",
        "    if len(classes) == 0:\n",
        "        return dict(status=\"no_polygon_classes\", msg=\"no polygon classes parsed\")\n",
        "\n",
        "    canvas_w = int(global_max_x // downscale) + 1\n",
        "    canvas_h = int(global_max_y // downscale) + 1\n",
        "\n",
        "    # rasterize\n",
        "    thumbnail_img, tissue_mask = rasterize_polygons_to_canvas(classes, canvas_w, canvas_h, downscale)\n",
        "\n",
        "    # find tumor class (case-insensitive startswith 'tumor')\n",
        "    tumor_key = next((k for k in classes.keys() if k and k.lower().startswith(\"tumor\")), None)\n",
        "    if tumor_key is None:\n",
        "        # fallback: pick largest class by pixel area (approx)\n",
        "        # approximate area by rasterizing each class quickly\n",
        "        class_areas = {}\n",
        "        for k, polys in classes.items():\n",
        "            m = Image.new(\"L\", (canvas_w, canvas_h), 0)\n",
        "            d = ImageDraw.Draw(m)\n",
        "            for poly in polys:\n",
        "                if not poly: continue\n",
        "                outer = poly[0] if isinstance(poly, list) and len(poly)>0 else poly\n",
        "                pts = [to_mask_coord_floor(x,y,downscale) for x,y in outer]\n",
        "                pts_clamped = [ (max(0,min(canvas_w-1,xx)), max(0,min(canvas_h-1,yy))) for xx,yy in pts ]\n",
        "                if len(pts_clamped)>=3:\n",
        "                    try:\n",
        "                        d.polygon(pts_clamped, outline=1, fill=1)\n",
        "                    except Exception:\n",
        "                        pass\n",
        "            class_areas[k] = np.array(m).sum()\n",
        "        # choose largest non-zero class\n",
        "        sorted_cls = sorted(class_areas.items(), key=lambda kv: kv[1], reverse=True)\n",
        "        if sorted_cls and sorted_cls[0][1] > 0:\n",
        "            tumor_key = sorted_cls[0][0]\n",
        "        else:\n",
        "            return dict(status=\"no_tumor_polygons\", msg=f\"no tumor-like class found; class_areas={class_areas}\")\n",
        "\n",
        "    tumor_polys = classes[tumor_key]\n",
        "\n",
        "    # create masks\n",
        "    tumor_mask_raw = make_downscaled_tumor_mask(tumor_polys, downscale, canvas_w, canvas_h)\n",
        "    tumor_mask_proc, labeled_mask = postprocess_mask(tumor_mask_raw,\n",
        "                                                     gaussian_sigma=gaussian_sigma,\n",
        "                                                     dilation_iters=dilation_iters,\n",
        "                                                     min_component_size=min_component_size)\n",
        "\n",
        "    zone2 = get_zone_two(tumor_mask_proc, dilation_size=zone2_dilation_size)\n",
        "    zone3_raw = (1 - np.clip(tumor_mask_proc + zone2, 0, 1)).astype(np.uint8)\n",
        "    if restrict_zone3_to_tissue:\n",
        "        zone3 = (zone3_raw & (tissue_mask > 0).astype(np.uint8)).astype(np.uint8)\n",
        "    else:\n",
        "        zone3 = zone3_raw\n",
        "\n",
        "    # save outputs into per_wsi_csv_folder/wsi_id\n",
        "    wsi_out_dir = per_wsi_csv_folder / wsi_id\n",
        "    wsi_out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    np.save(wsi_out_dir / \"tumor_mask_raw.npy\", tumor_mask_raw)\n",
        "    np.save(wsi_out_dir / \"tumor_mask_processed.npy\", tumor_mask_proc)\n",
        "    np.save(wsi_out_dir / \"zone2.npy\", zone2)\n",
        "    np.save(wsi_out_dir / \"zone3.npy\", zone3)\n",
        "    try:\n",
        "        thumbnail_img.save(wsi_out_dir / \"thumbnail_from_geojson.png\")\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # centroid assignment & counts (same as before)\n",
        "    zone_counts = defaultdict(int)\n",
        "    zone_class_counts = defaultdict(int)\n",
        "    total_polygons = 0\n",
        "    oob = 0\n",
        "    for feat in features:\n",
        "        if not isinstance(feat, dict): continue\n",
        "        props = feat.get(\"properties\", {}) or {}\n",
        "        cls_field = props.get(\"classification\", props.get(\"class\"))\n",
        "        if isinstance(cls_field, dict):\n",
        "            class_name = cls_field.get(\"name\", \"Unknown\")\n",
        "        else:\n",
        "            class_name = str(cls_field) if cls_field is not None else \"Unknown\"\n",
        "        geom = feat.get(\"geometry\", {}) or {}\n",
        "        gtype = geom.get(\"type\")\n",
        "        coords = geom.get(\"coordinates\") or []\n",
        "        if gtype == \"Polygon\":\n",
        "            poly_list = [coords]\n",
        "        elif gtype == \"MultiPolygon\":\n",
        "            poly_list = coords\n",
        "        else:\n",
        "            poly_list = []\n",
        "        for poly in poly_list:\n",
        "            total_polygons += 1\n",
        "            if not poly: continue\n",
        "            outer = poly[0] if isinstance(poly, list) and len(poly)>0 else poly\n",
        "            cx_full, cy_full = centroid_of_ring(outer)\n",
        "            if cx_full is None:\n",
        "                continue\n",
        "            mx, my = to_mask_coord_floor(cx_full, cy_full, downscale)\n",
        "            if not (0 <= mx < canvas_w and 0 <= my < canvas_h):\n",
        "                oob += 1\n",
        "                continue\n",
        "            if tumor_mask_proc[my, mx] == 1:\n",
        "                zone = \"zone1\"\n",
        "            elif zone2[my, mx] == 1:\n",
        "                zone = \"zone2\"\n",
        "            elif zone3[my, mx] == 1:\n",
        "                zone = \"zone3\"\n",
        "            else:\n",
        "                zone = \"unassigned\"\n",
        "            zone_counts[zone] += 1\n",
        "            zone_class_counts[(class_name, zone)] += 1\n",
        "\n",
        "    # build per-wsi rows and save small CSV\n",
        "    classes_seen = sorted({c for (c,z) in zone_class_counts.keys()})\n",
        "    per_wsi_rows = []\n",
        "    for cls in classes_seen:\n",
        "        r = {\n",
        "            \"wsi_id\": wsi_id,\n",
        "            \"class\": cls,\n",
        "            \"zone1_count\": int(zone_class_counts.get((cls, \"zone1\"), 0)),\n",
        "            \"zone2_count\": int(zone_class_counts.get((cls, \"zone2\"), 0)),\n",
        "            \"zone3_count\": int(zone_class_counts.get((cls, \"zone3\"), 0)),\n",
        "            \"total_polygons_assigned\": int(sum(zone_class_counts.get((cls, z), 0) for z in [\"zone1\",\"zone2\",\"zone3\"]))\n",
        "        }\n",
        "        per_wsi_rows.append(r)\n",
        "    if per_wsi_rows:\n",
        "        pd.DataFrame(per_wsi_rows).to_csv(wsi_out_dir / f\"{wsi_id}_zone_counts_dil5.csv\", index=False)\n",
        "\n",
        "    # optional QC overlay (skip failures)\n",
        "    if save_qc_images:\n",
        "        try:\n",
        "            W,H = canvas_w, canvas_h\n",
        "            base = thumbnail_img.convert(\"RGBA\").resize((canvas_w, canvas_h), Image.LANCZOS)\n",
        "            overlay = Image.new(\"RGBA\", (canvas_w, canvas_h), (0,0,0,0))\n",
        "            def paste_mask(m, color_rgb, alpha=0.45):\n",
        "                if m.sum() == 0: return\n",
        "                mask_img = Image.fromarray((m*255).astype(\"uint8\")).convert(\"L\")\n",
        "                color_img = Image.new(\"RGBA\", (canvas_w, canvas_h), color_rgb + (int(alpha*255),))\n",
        "                overlay.paste(color_img, (0,0), mask_img)\n",
        "            paste_mask(zone3, (0,180,0), 0.35)\n",
        "            paste_mask(zone2, (255,210,0), 0.45)\n",
        "            paste_mask(tumor_mask_proc, (220,20,60), 0.5)\n",
        "            composite = Image.alpha_composite(base, overlay)\n",
        "            composite.save(wsi_out_dir / f\"{wsi_id}_zones_overlay_dil5.png\")\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    return dict(status=\"ok\", msg=f\"processed {wsi_id}\")\n",
        "\n",
        "# ------------- main: compare and re-run for missing WSIs -------------\n",
        "if __name__ == \"__main__\":\n",
        "    input_wsis = list_input_wsis(ROOT)\n",
        "    output_wsis = list_output_wsis(per_wsi_csv_folder)\n",
        "    missing = sorted([w for w in input_wsis if w not in output_wsis])\n",
        "    print(f\"Input WSI count: {len(input_wsis)}\")\n",
        "    print(f\"Output WSI count (folders found under {per_wsi_csv_folder}): {len(output_wsis)}\")\n",
        "    print(f\"Missing (to process): {len(missing)}\")\n",
        "\n",
        "    # save missing list\n",
        "    pd.DataFrame({\"missing_wsi\": missing}).to_csv(out_dir / \"missing_wsis.csv\", index=False)\n",
        "\n",
        "    # process each missing WSI serially (you can parallelize later)\n",
        "    errors = []\n",
        "    for i, wsi in enumerate(missing, start=1):\n",
        "        print(f\"\\n[{i}/{len(missing)}] processing missing WSI: {wsi}\")\n",
        "        try:\n",
        "            res = run_one_wsi_by_id(wsi)\n",
        "            if res.get(\"status\") != \"ok\":\n",
        "                print(\" SKIPPED:\", res)\n",
        "                errors.append({\"wsi\": wsi, \"status\": res.get(\"status\"), \"msg\": res.get(\"msg\")})\n",
        "            else:\n",
        "                print(\" DONE:\", res.get(\"msg\"))\n",
        "        except Exception as e:\n",
        "            tb = traceback.format_exc()\n",
        "            print(\" ERROR running:\", e)\n",
        "            errors.append({\"wsi\": wsi, \"status\": \"exception\", \"msg\": str(e), \"trace\": tb})\n",
        "\n",
        "    if errors:\n",
        "        pd.DataFrame(errors).to_csv(out_dir / \"faulty_wsis_missing_run.csv\", index=False)\n",
        "        print(\"Some WSIs failed; saved report to faulty_wsis_missing_run.csv\")\n",
        "    else:\n",
        "        print(\"All missing WSIs processed successfully.\")\n",
        "\n",
        "    print(\"Finished.\")"
      ],
      "metadata": {
        "id": "DqtsfHHTGtbX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}